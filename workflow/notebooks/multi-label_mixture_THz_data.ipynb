{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9472f796",
   "metadata": {},
   "source": [
    "# A notebook to demonstrate creation and handling of a small set of random THz mixture data. Then using them for multi-label classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4031617b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-15 21:27:28.046048: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-07-15 21:27:28.955757: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-07-15 21:27:28.985007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:65:00.0 name: Quadro RTX 4000 computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 36 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 387.49GiB/s\n",
      "2022-07-15 21:27:28.985066: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-07-15 21:27:28.990593: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-07-15 21:27:28.990686: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-07-15 21:27:28.991987: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-07-15 21:27:28.992342: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-07-15 21:27:28.993118: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-07-15 21:27:28.994036: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-07-15 21:27:28.994177: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-07-15 21:27:28.994716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-07-15 21:27:28.995217: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-15 21:27:28.996041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:65:00.0 name: Quadro RTX 4000 computeCapability: 7.5\n",
      "coreClock: 1.545GHz coreCount: 36 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 387.49GiB/s\n",
      "2022-07-15 21:27:28.996491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-07-15 21:27:28.996541: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-07-15 21:27:29.412800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-07-15 21:27:29.412823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-07-15 21:27:29.412828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-07-15 21:27:29.413541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 81 MB memory) -> physical GPU (device: 0, name: Quadro RTX 4000, pci bus id: 0000:65:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns  #heat map\n",
    "import glob # batch processing of images\n",
    "\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix    #confusion matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Collect all the font names available to matplotlib\n",
    "font_names = [f.name for f in fm.fontManager.ttflist]\n",
    "# print(font_names)\n",
    "\n",
    "from scipy import signal\n",
    "from scipy import interpolate\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "#Sklearn model saving and loading\n",
    "from joblib import dump, load\n",
    "\n",
    "if '../../' not in sys.path:\n",
    "    sys.path.append('../../')\n",
    "\n",
    "from aimos.spectral_datasets.THz_datasets import THz_data\n",
    "from aimos.spectral_datasets.THz_mixture_data import THz_mixture_data\n",
    "from aimos.misc.utils import simple_plotter\n",
    "\n",
    "\n",
    "#Set random seed\n",
    "os.environ['PYTHONHASHSEED'] = str(42)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "tf.random.set_seed(42)  \n",
    "tf.random.get_global_generator().reset_from_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b69f7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concentrations_to_one_hot_encode(y):\n",
    "    '''\n",
    "    args:\n",
    "    y, a vector containing the concentration values for each component.\n",
    "    \n",
    "    return vector containing binary one hot encoding\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    y_ohe = y\n",
    "    for i in range(y.shape[0]):\n",
    "\n",
    "        for j in range(y.shape[1]):\n",
    "            if y[i][j] > 0:\n",
    "                y_ohe[i][j]=1    \n",
    "                \n",
    "    return y_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47e9f5e",
   "metadata": {},
   "source": [
    "# Create controlled test mixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4fd26ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Components :  [[ 0  1  2  3  4  5  6  7  8  9 10 11 12]]\n",
      "Components shape :  (1, 13)\n",
      "Number of Compounds: 12\n",
      "Number of Spectrum: 164\n",
      "Total Number of Spectra: 1968\n",
      "Sample Size of training data: 229\n",
      "Rows discarded: 22\n",
      "Resolution (1/cm) =  0.016\n",
      "Loading CH3Cl... \n",
      "CH3Cl Data in Memory \n",
      "Loading CH3OH... \n",
      "CH3OH Data in Memory \n",
      "Loading HCOOH... \n",
      "HCOOH Data in Memory \n",
      "Loading H2CO... \n",
      "H2CO Data in Memory \n",
      "Loading H2S... \n",
      "H2S Data in Memory \n",
      "Loading SO2... \n",
      "SO2 Data in Memory \n",
      "Loading OCS... \n",
      "OCS Data in Memory \n",
      "Loading HCN... \n",
      "HCN Data in Memory \n",
      "Loading CH3CN... \n",
      "CH3CN Data in Memory \n",
      "Loading HNO3... \n",
      "HNO3 Data in Memory \n",
      "Loading C2H5OH... \n",
      "C2H5OH Data in Memory \n",
      "Loading CH3CHO... \n",
      "CH3CHO Data in Memory \n",
      "shape of spectra (features): (1968, 229)\n",
      "shape of labels: (1968,)\n",
      "labels :  [' ', '', 'Diluent', '$C_2H_5OH$', '$CH_3CHO$', '$CH_3Cl$', '$CH_3CN$', '$CH_3OH$', '$H_2CO$', '$H_2S$', '$HCN$', '$HCOOH$', '$HNO_3$', '$OCS$', '$SO_2$']\n",
      "Basis shape: (12, 229)\n"
     ]
    }
   ],
   "source": [
    "m = THz_mixture_data(resolution=0.016, pressure='1 Torr', verbosity=True)\n",
    "m.initiate_THz_mixture_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9325b44c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ...generating 1-component mixtures data...\n",
      "\n",
      "\n",
      " ...generating 2-component mixtures data...\n",
      "\n",
      "\n",
      " ...generating 3-component mixtures data...\n",
      "\n",
      "\n",
      " ...generating 4-component mixtures data...\n",
      "\n",
      "\n",
      " ...generating 5-component mixtures data...\n",
      "\n",
      "\n",
      " ...generating 6-component mixtures data...\n",
      "\n",
      "\n",
      " ...generating 7-component mixtures data...\n",
      "\n",
      "\n",
      " ...generating 8-component mixtures data...\n",
      "\n",
      "\n",
      " ...generating 9-component mixtures data...\n",
      "\n",
      "\n",
      " ...generating 10-component mixtures data...\n",
      "\n",
      "\n",
      " ...generating 11-component mixtures data...\n",
      "\n",
      "\n",
      " ...generating 12-component mixtures data...\n",
      "\n",
      "Time elasped: 67.017\n",
      "Total number of test mixtures :  1200\n",
      "\n",
      "Combined test simulated mixtures\n",
      "\n",
      "No. of test mixtures:  1200\n",
      "test_targets data type:  object\n",
      "test_targets data shape:  (1200, 12)\n",
      "Time elaspsed:  143.76\n",
      "numpy random state:  4170550853\n",
      "test_mixtures data type:  object\n",
      "test_mixtures shape:  (1197, 1, 229)\n",
      "test_targets data type:  object\n",
      "test_targets shape:  (1197, 12)\n",
      "Adjusted n_test_mixtures:  1197\n",
      "Total spectra with weak components in testing dataset: (81,)\n",
      "test_mixtures data type:  object\n",
      "test_mixtures shape:  (1116, 12)\n",
      "test_targets data type:  object\n",
      "test_targets shape:  (1116, 12)\n",
      "Adjusted n_test_mixtures after removing spectra with weak components:  1116\n"
     ]
    }
   ],
   "source": [
    "m.make_controlled_test_mixtures(equal_amount = 100, tweleve_component_amount=100,\n",
    "                                abs_threshold=0.001, test_Species_Abs_Threshold=0.0001,\n",
    "                                save_to_file = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3456b433",
   "metadata": {},
   "source": [
    "# view attributes of the controlled test mixtures data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2809ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of test mixtures:  1116\n",
      "test mixtures shape:  (1116, 229)\n",
      "test targets shape:  (1116, 12)\n",
      "test dilutions shape:  (1200,)\n",
      "resolution:  0.016\n",
      "frequencies in the data [ 7.352  7.368  7.384  7.4    7.416  7.432  7.448  7.464  7.48   7.496\n",
      "  7.512  7.528  7.544  7.56   7.576  7.592  7.608  7.624  7.64   7.656\n",
      "  7.672  7.688  7.704  7.72   7.736  7.752  7.768  7.784  7.8    7.816\n",
      "  7.832  7.848  7.864  7.88   7.896  7.912  7.928  7.944  7.96   7.976\n",
      "  7.992  8.008  8.024  8.04   8.056  8.072  8.088  8.104  8.12   8.136\n",
      "  8.152  8.168  8.184  8.2    8.216  8.232  8.248  8.264  8.28   8.296\n",
      "  8.312  8.328  8.344  8.36   8.376  8.392  8.408  8.424  8.44   8.456\n",
      "  8.472  8.488  8.504  8.52   8.536  8.552  8.568  8.584  8.6    8.616\n",
      "  8.632  8.648  8.664  8.68   8.696  8.712  8.728  8.744  8.76   8.776\n",
      "  8.792  8.808  8.824  8.84   8.856  8.872  8.888  8.904  8.92   8.936\n",
      "  8.952  8.968  8.984  9.     9.016  9.032  9.048  9.064  9.08   9.096\n",
      "  9.112  9.128  9.144  9.16   9.176  9.192  9.208  9.224  9.24   9.256\n",
      "  9.272  9.288  9.304  9.32   9.336  9.352  9.368  9.384  9.4    9.416\n",
      "  9.432  9.448  9.464  9.48   9.496  9.512  9.528  9.544  9.56   9.576\n",
      "  9.592  9.608  9.624  9.64   9.656  9.672  9.688  9.704  9.72   9.736\n",
      "  9.752  9.768  9.784  9.8    9.816  9.832  9.848  9.864  9.88   9.896\n",
      "  9.912  9.928  9.944  9.96   9.976  9.992 10.008 10.024 10.04  10.056\n",
      " 10.072 10.088 10.104 10.12  10.136 10.152 10.168 10.184 10.2   10.216\n",
      " 10.232 10.248 10.264 10.28  10.296 10.312 10.328 10.344 10.36  10.376\n",
      " 10.392 10.408 10.424 10.44  10.456 10.472 10.488 10.504 10.52  10.536\n",
      " 10.552 10.568 10.584 10.6   10.616 10.632 10.648 10.664 10.68  10.696\n",
      " 10.712 10.728 10.744 10.76  10.776 10.792 10.808 10.824 10.84  10.856\n",
      " 10.872 10.888 10.904 10.92  10.936 10.952 10.968 10.984 11.   ]\n",
      "pressure:  1 Torr\n",
      "labels:  [' ', '', 'Diluent', '$C_2H_5OH$', '$CH_3CHO$', '$CH_3Cl$', '$CH_3CN$', '$CH_3OH$', '$H_2CO$', '$H_2S$', '$HCN$', '$HCOOH$', '$HNO_3$', '$OCS$', '$SO_2$']\n",
      "label_id:  [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "number of features:  229\n",
      "no. of compounds:  12\n",
      "no. of spectrum per compound in pure THz data:  164\n",
      "no. of spectra in pure THz data:  1968\n",
      "number ot maximum mixture components:  12\n",
      "integer indices for each of the mixture components [[ 0  1  2  3  4  5  6  7  8  9 10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "print('number of test mixtures: ',m.n_test_mixtures)\n",
    "print('test mixtures shape: ',m.test_mixtures.shape)\n",
    "print('test targets shape: ',m.test_targets.shape)\n",
    "print('test dilutions shape: ',m.test_dilution.shape)\n",
    "\n",
    "print('resolution: ',m.resolution)\n",
    "print('frequencies in the data', m.frequencies)\n",
    "\n",
    "print('pressure: ',m.pressure) \n",
    "print('labels: ',m.labels) \n",
    "print('label_id: ',m.label_id) \n",
    "\n",
    "print('number of features: ',m.n_features) \n",
    "print('no. of compounds: ',m.n_compounds)\n",
    "print('no. of spectrum per compound in pure THz data: ' ,m.n_spectrum)\n",
    "print('no. of spectra in pure THz data: ',m.n_spectra) \n",
    "\n",
    "print('number ot maximum mixture components: ',m.n_mixture_component_max)\n",
    "print('integer indices for each of the mixture components',m.components)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b6c646",
   "metadata": {},
   "source": [
    "# assign controlled test mixtures data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce39ad49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1116, 229)\n",
      "y shape: (1116, 12)\n",
      "X dtype: object\n",
      "y dtype: object\n",
      "After data type conversion\n",
      "X dtype: float64\n",
      "y dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_303366/2528633035.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X=X.astype(np.float)\n",
      "/tmp/ipykernel_303366/2528633035.py:12: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y=y.astype(np.float)\n"
     ]
    }
   ],
   "source": [
    "X=m.test_mixtures\n",
    "\n",
    "y=m.test_targets\n",
    "\n",
    "print('X shape:', X.shape)\n",
    "print('y shape:', y.shape)\n",
    "\n",
    "print('X dtype:', X.dtype)\n",
    "print('y dtype:', y.dtype)\n",
    "\n",
    "X=X.astype(np.float)\n",
    "y=y.astype(np.float)\n",
    "\n",
    "print('After data type conversion')\n",
    "print('X dtype:', X.dtype)\n",
    "print('y dtype:', y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "896d5dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ohe = concentrations_to_one_hot_encode(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71abcbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      "[0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "[1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0.]\n",
      "[0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1.]\n",
      "[0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.]\n",
      "[0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      "[1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "[0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0.]\n",
      "[0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      "[0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.]\n",
      "[0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
      "[0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1.]\n",
      "[0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0.]\n",
      "[1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "[0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1.]\n",
      "[1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1.]\n",
      "[1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1.]\n",
      "[1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1.]\n",
      "[1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1.]\n",
      "[1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1.]\n",
      "[1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "[1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "[1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1.]\n",
      "[1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.]\n",
      "[0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0.]\n",
      "[0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      "[0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
      "[0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1.]\n",
      "[0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0.]\n",
      "[0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0.]\n",
      "[1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "[1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.]\n",
      "[0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1.]\n",
      "[0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0.]\n",
      "[0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1.]\n",
      "[1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.]\n",
      "[0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0.]\n",
      "[0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "[0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0.]\n",
      "[0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      "[0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0.]\n",
      "[1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.]\n",
      "[1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0.]\n",
      "[0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0.]\n",
      "[0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1.]\n",
      "[0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1.]\n",
      "[0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1.]\n",
      "[0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0.]\n",
      "[0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0.]\n",
      "[1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0.]\n",
      "[0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1.]\n",
      "[1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1.]\n",
      "[1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1.]\n",
      "[0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0.]\n",
      "[1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0.]\n",
      "[0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1.]\n",
      "[0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1.]\n",
      "[1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0.]\n",
      "[1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1.]\n",
      "[0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0.]\n",
      "[1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1.]\n",
      "[0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1.]\n",
      "[1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1.]\n",
      "[0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1.]\n",
      "[1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1.]\n",
      "[0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0.]\n",
      "[0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0.]\n",
      "[0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1.]\n",
      "[0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0.]\n",
      "[0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1.]\n",
      "[1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0.]\n",
      "[0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1.]\n",
      "[0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0.]\n",
      "[0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0.]\n",
      "[0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0.]\n",
      "[0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0.]\n",
      "[1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1.]\n",
      "[1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0.]\n",
      "[1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "[0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0.]\n",
      "[0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0.]\n",
      "[1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0.]\n",
      "[0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1.]\n",
      "[1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1.]\n",
      "[0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0.]\n",
      "[0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1.]\n",
      "[0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
      "[1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1.]\n",
      "[0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1.]\n",
      "[1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1.]\n",
      "[1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0.]\n",
      "[0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
      "[1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1.]\n",
      "[0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0.]\n",
      "[1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0.]\n",
      "[0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0.]\n",
      "[0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "[0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0.]\n",
      "[0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.]\n",
      "[1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1.]\n",
      "[0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0.]\n",
      "[1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1.]\n",
      "[1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1.]\n",
      "[0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0.]\n",
      "[1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0.]\n",
      "[0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1.]\n",
      "[0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0.]\n",
      "[0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1.]\n",
      "[0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1.]\n",
      "[0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0.]\n",
      "[0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1.]\n",
      "[1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0.]\n",
      "[0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1.]\n",
      "[1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1.]\n",
      "[0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0.]\n",
      "[1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0.]\n",
      "[1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0.]\n",
      "[1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0.]\n",
      "[1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0.]\n",
      "[1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1.]\n",
      "[1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0.]\n",
      "[1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0.]\n",
      "[1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1.]\n",
      "[0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1.]\n",
      "[0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
      "[0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0.]\n",
      "[1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0.]\n",
      "[0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "[0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1.]\n",
      "[0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1.]\n",
      "[0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1.]\n",
      "[0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1.]\n",
      "[0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1.]\n",
      "[0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "[0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "[0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0.]\n",
      "[0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1.]\n",
      "[1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1.]\n",
      "[1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1.]\n",
      "[1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0.]\n",
      "[0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1.]\n",
      "[1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0.]\n",
      "[1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "[0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1.]\n",
      "[0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1.]\n",
      "[0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0.]\n",
      "[1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0.]\n",
      "[0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.]\n",
      "[1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "[0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1.]\n",
      "[1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0.]\n",
      "[0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1.]\n",
      "[1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1.]\n",
      "[0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1.]\n",
      "[1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1.]\n",
      "[0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1.]\n",
      "[0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1.]\n",
      "[1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0.]\n",
      "[1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0.]\n",
      "[0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1.]\n",
      "[0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0.]\n",
      "[0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0.]\n",
      "[1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0.]\n",
      "[0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0.]\n",
      "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0.]\n",
      "[0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1.]\n",
      "[1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1.]\n",
      "[0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1.]\n",
      "[1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1.]\n",
      "[0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0.]\n",
      "[1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1.]\n",
      "[1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0.]\n",
      "[1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1.]\n",
      "[0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1.]\n",
      "[0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0.]\n",
      "[1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0.]\n",
      "[0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1.]\n",
      "[0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0.]\n",
      "[1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1.]\n",
      "[0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0.]\n",
      "[1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1.]\n",
      "[1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1.]\n",
      "[0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0.]\n",
      "[1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0.]\n",
      "[1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1.]\n",
      "[1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1.]\n",
      "[0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1.]\n",
      "[1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1.]\n",
      "[1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      "[1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1.]\n",
      "[1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0.]\n",
      "[1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0.]\n",
      "[0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0.]\n",
      "[0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0.]\n",
      "[1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0.]\n",
      "[0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1.]\n",
      "[0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1.]\n",
      "[1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1.]\n",
      "[1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0.]\n",
      "[0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1.]\n",
      "[1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0.]\n",
      "[0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1.]\n",
      "[1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0.]\n",
      "[0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1.]\n",
      "[0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0.]\n",
      "[1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0.]\n",
      "[1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1.]\n",
      "[1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1.]\n",
      "[1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1.]\n",
      "[1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0.]\n",
      "[1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 0.]\n",
      "[0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1.]\n",
      "[1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0.]\n",
      "[1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1.]\n",
      "[1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1.]\n",
      "[1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1.]\n",
      "[1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "[1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1.]\n",
      "[0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1.]\n",
      "[0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 1.]\n",
      "[0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1.]\n",
      "[1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "[0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      "[1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0.]\n",
      "[1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0.]\n",
      "[1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0.]\n",
      "[1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0.]\n",
      "[1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0.]\n",
      "[0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1.]\n",
      "[0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0.]\n",
      "[0. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0.]\n",
      "[0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0.]\n",
      "[1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.]\n",
      "[0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0.]\n",
      "[0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1.]\n",
      "[1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0.]\n",
      "[1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1.]\n",
      "[1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0.]\n",
      "[1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0.]\n",
      "[0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "[1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0.]\n",
      "[1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1.]\n",
      "[0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0.]\n",
      "[1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0.]\n",
      "[0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.]\n",
      "[1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      "[1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0.]\n",
      "[1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1.]\n",
      "[0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1.]\n",
      "[1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1.]\n",
      "[1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0.]\n",
      "[1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0.]\n",
      "[0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0.]\n",
      "[0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0.]\n",
      "[0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "[0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1.]\n",
      "[0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0.]\n",
      "[1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0.]\n",
      "[1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0.]\n",
      "[0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "[0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.]\n",
      "[0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1.]\n",
      "[0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0.]\n",
      "[1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1.]\n",
      "[1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0.]\n",
      "[0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1.]\n",
      "[0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1.]\n",
      "[0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1.]\n",
      "[1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1.]\n",
      "[1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0.]\n",
      "[1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0.]\n",
      "[0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 0.]\n",
      "[1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "[0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "[0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n",
      "[1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0.]\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0.]\n",
      "[1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1.]\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
      "[1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0.]\n",
      "[0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n",
      "[1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
      "[1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1.]\n",
      "[0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0.]\n",
      "[1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0.]\n",
      "[0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "[0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0.]\n",
      "[0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1.]\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.]\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.]\n",
      "[1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1.]\n",
      "[1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "[1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1.]\n",
      "[1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1.]\n",
      "[1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "[1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(y_ohe.shape[0]):\n",
    "    \n",
    "        print(y_ohe[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc09995e",
   "metadata": {},
   "source": [
    "# preview one test mixture spectra using simple plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bfcb777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x210 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "simple_plotter(m.frequencies,m.test_mixtures[0],linewidth=0.5,color='black',label='$test-mixture$', \n",
    "                   majorsize=6,minorsize=2,width=1, labelsize=8,legendsize=3, legendloc=2,  \n",
    "                   labelpad=4,fontsize='medium',fontweight='bold',\n",
    "                  xmajormplloc=0.5,xminormplloc=0.2, tickdirection='out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f5bd343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.modeling\n",
    "\n",
    "\n",
    "\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "\n",
    "def get_callbacks(name):\n",
    "    return [\n",
    "    tfdocs.modeling.EpochDots(),\n",
    "#     tf.keras.callbacks.EarlyStopping(monitor='val_SparseCatCrossentropy', patience=100),\n",
    "    tf.keras.callbacks.TensorBoard(logdir/name),\n",
    "  ]\n",
    "\n",
    "def get_optimizer():\n",
    "    return tf.keras.optimizers.Adam()\n",
    "\n",
    "def compile_and_fit(model, name, x_train, y_train, x_test, y_test, STEPS_PER_EPOCH,  optimizer=None, max_epochs=200):\n",
    "    if optimizer is None:\n",
    "        optimizer = get_optimizer()\n",
    "    model.compile(optimizer=optimizer,\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            metrics=[\n",
    "              tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                  from_logits=True, name='SparseCatCrossentropy'),\n",
    "              'accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    steps_per_epoch = STEPS_PER_EPOCH,\n",
    "    epochs=max_epochs,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=get_callbacks(name),\n",
    "    verbose=0)\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "\n",
    "def voc_net_style_model():\n",
    "\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # C1 Convolutional Layer\n",
    "    model.add(layers.Conv1D(filters = 3 , kernel_size=3, activation='relu', input_shape=(229, 1), name = 'C1') )\n",
    "\n",
    "    # S2 Subsampling Layer\n",
    "    model.add(layers.AveragePooling1D(pool_size = 2, strides = 2, padding = 'valid', name = 'S2'))\n",
    "    \n",
    "    # C3 Convolutional Layer\n",
    "    model.add(layers.Conv1D(filters = 3 , kernel_size=3, activation='relu', name = 'C3') )\n",
    "\n",
    "    # Flatten the CNN output to feed it with fully connected layers\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.add(layers.Dense(48, activation='relu')) \n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(12))  # number of dense layer would be equal to number of classess\n",
    "    \n",
    "\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 metrics=[\n",
    "              tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                  from_logits=True, name='SparseCatCrossentropy'),\n",
    "              'accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19016b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 229)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b2c3e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 1116)\n"
     ]
    }
   ],
   "source": [
    "global_indices=range(0, X.shape[0])\n",
    "print(global_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f19f87ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (669, 229, 1)\n",
      "y_ohe_train shape: (669, 12)\n",
      "X_test shape: (447, 229, 1)\n",
      "y_ohe_test shape: (447, 12)\n"
     ]
    }
   ],
   "source": [
    "#split intro train and test set\n",
    "\n",
    "#seeds used 123,237, 786\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "\n",
    "\n",
    "TRAIN_SIZE=0.60\n",
    "TEST_SIZE=1-TRAIN_SIZE\n",
    "\n",
    "x_train, x_test, y_train, y_test, train_indices, test_indices = train_test_split(np.expand_dims(X,-1), y_ohe, global_indices, train_size=TRAIN_SIZE,\n",
    "                                                   test_size=TEST_SIZE,\n",
    "                                                   random_state=786\n",
    "                                                   \n",
    "                                                   )\n",
    "\n",
    "print('X_train shape:', x_train.shape)\n",
    "print('y_ohe_train shape:', y_train.shape)\n",
    "\n",
    "print('X_test shape:', x_test.shape)\n",
    "print('y_ohe_test shape:', y_test.shape)\n",
    "\n",
    "\n",
    "# print(\"All:\", np.bincount(y) / float(len(y))*100  )\n",
    "# print(\"Training:\", np.bincount(y_train) / float(len(y_train))*100  )\n",
    "# print(\"Testing:\", np.bincount(y_test) / float(len(y_test))*100  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1d6bbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "C1 (Conv1D)                  (None, 227, 3)            12        \n",
      "_________________________________________________________________\n",
      "S2 (AveragePooling1D)        (None, 113, 3)            0         \n",
      "_________________________________________________________________\n",
      "C3 (Conv1D)                  (None, 111, 3)            30        \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 333)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 48)                16032     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 48)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 12)                588       \n",
      "=================================================================\n",
      "Total params: 16,662\n",
      "Trainable params: 16,662\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = voc_net_style_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "508f61e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 train_step\n        loss = self.compiled_loss(\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:155 __call__\n        losses = call_fn(y_true, y_pred)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:259 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:1712 sparse_categorical_crossentropy\n        return backend.sparse_categorical_crossentropy(\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:4979 sparse_categorical_crossentropy\n        res = nn.sparse_softmax_cross_entropy_with_logits_v2(\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:4228 sparse_softmax_cross_entropy_with_logits_v2\n        return sparse_softmax_cross_entropy_with_logits(\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:4133 sparse_softmax_cross_entropy_with_logits\n        raise ValueError(\"Shape mismatch: The shape of labels (received %s) \"\n\n    ValueError: Shape mismatch: The shape of labels (received (384,)) should equal the shape of logits except for the last dimension (received (32, 12)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/CPU:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      3\u001b[0m     stop_early \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseCatCrossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mstop_early\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1183\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1178\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1179\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1180\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1181\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1182\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1183\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1184\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1185\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 889\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    891\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    892\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    931\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    932\u001b[0m   initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 933\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    935\u001b[0m   \u001b[38;5;66;03m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    936\u001b[0m   \u001b[38;5;66;03m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    937\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:763\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    764\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    767\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3050\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3049\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 3050\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3051\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3444\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3440\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3441\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[0;32m-> 3444\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3445\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mprimary[cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[1;32m   3447\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3279\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3274\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3275\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3276\u001b[0m ]\n\u001b[1;32m   3277\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3278\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3279\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3280\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3281\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3282\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3284\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3287\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3288\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3291\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3292\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3293\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3294\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3295\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3296\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:999\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    997\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m--> 999\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m   1004\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:672\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    669\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    670\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    671\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 672\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    673\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:986\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    985\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 986\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    987\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:855 train_function  *\n        return step_function(self, iterator)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:845 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:838 run_step  **\n        outputs = model.train_step(data)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 train_step\n        loss = self.compiled_loss(\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:155 __call__\n        losses = call_fn(y_true, y_pred)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:259 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:1712 sparse_categorical_crossentropy\n        return backend.sparse_categorical_crossentropy(\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:4979 sparse_categorical_crossentropy\n        res = nn.sparse_softmax_cross_entropy_with_logits_v2(\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:4228 sparse_softmax_cross_entropy_with_logits_v2\n        return sparse_softmax_cross_entropy_with_logits(\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    /home/reshad812/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:4133 sparse_softmax_cross_entropy_with_logits\n        raise ValueError(\"Shape mismatch: The shape of labels (received %s) \"\n\n    ValueError: Shape mismatch: The shape of labels (received (384,)) should equal the shape of logits except for the last dimension (received (32, 12)).\n"
     ]
    }
   ],
   "source": [
    "# run on CPU for reproducibility, best epoch is 4.\n",
    "with tf.device('/CPU:0'):\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='SparseCatCrossentropy', patience=5)\n",
    "    history = model.fit(x_train, y_train, epochs=4, validation_data=(x_test, y_test), callbacks=[stop_early])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f743c720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(672, 12)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "13874c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 1., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 1., 0.],\n",
       "       [1., 1., 1., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8210f6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "\n",
    "# this will generate a random multi-label dataset\n",
    "p, q = make_multilabel_classification(sparse = False, n_features=229, n_classes=12, n_labels=5, allow_unlabeled = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "268fde39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "20237a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(672, 229)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(x_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7aa7e6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using binary relevance\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# initialize binary relevance multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "classifier = BinaryRelevance(GaussianNB())\n",
    "\n",
    "# train\n",
    "# classifier.fit(p, q)\n",
    "classifier.fit(np.squeeze(x_train), y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(np.squeeze(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9f092f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12723214285714285"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df87b31a",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2017/08/introduction-to-multi-label-classification\n",
    "\n",
    "\n",
    "Audio classification multilabel\n",
    "https://arxiv.org/pdf/1707.04916.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f4c5a38f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'rows'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [119]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# how many multi-labels are there\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m np\u001b[38;5;241m.\u001b[39munique(\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrows\u001b[49m)\u001b[38;5;241m.\u001b[39mshape, np\u001b[38;5;241m.\u001b[39munique(y_test\u001b[38;5;241m.\u001b[39mrows)\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'rows'"
     ]
    }
   ],
   "source": [
    "# how many multi-labels are there\n",
    "\n",
    "np.unique(y_train.rows).shape, np.unique(y_test.rows).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6d810926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.dataset import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c153480b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotions:train - does not exists downloading\n",
      "Downloaded emotions-train\n",
      "emotions:test - does not exists downloading\n",
      "Downloaded emotions-test\n"
     ]
    }
   ],
   "source": [
    "p_train, q_train, feature_names, label_names = load_dataset('emotions', 'train')\n",
    "p_test, q_test, _, _ =load_dataset('emotions', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cddde0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391, 72)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "29715335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 1, 1])], dtype=object)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_test[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b86aff43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((391, 6), (202, 6))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_train.shape, q_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f1023550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26,), (21,))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(q_train.rows).shape, np.unique(q_test.rows).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e86f3475",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Could not synchronize CUDA stream: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     16\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39mAdam(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m))\n\u001b[0;32m---> 18\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39msqueeze(x_test))\n\u001b[1;32m     21\u001b[0m preds[preds\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1133\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1127\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cluster_coordinator \u001b[38;5;241m=\u001b[39m cluster_coordinator\u001b[38;5;241m.\u001b[39mClusterCoordinator(\n\u001b[1;32m   1128\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy)\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mscope(), \\\n\u001b[1;32m   1131\u001b[0m      training_utils\u001b[38;5;241m.\u001b[39mRespectCompiledTrainableState(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1132\u001b[0m   \u001b[38;5;66;03m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[0;32m-> 1133\u001b[0m   data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m      \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m      \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m      \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m      \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1142\u001b[0m \u001b[43m      \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m      \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m      \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1149\u001b[0m   \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py:1364\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1363\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py:1150\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[0;32m-> 1150\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution_value \u001b[38;5;241m=\u001b[39m \u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m   1152\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_data_adapter_compatibility(adapter_cls)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:628\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    627\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 628\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    630\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1094\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \n\u001b[1;32m   1073\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1094\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1062\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1060\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numpy_internal()\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 1062\u001b[0m   \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_status_to_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Could not synchronize CUDA stream: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1500, activation='relu', input_dim=np.squeeze(x_train).shape[1]))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "\n",
    "# sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(lr=0.01, decay=1e-6))\n",
    "\n",
    "history = model.fit(np.squeeze(x_train), y_train, epochs=50, batch_size=50)\n",
    "\n",
    "preds = model.predict(np.squeeze(x_test))\n",
    "preds[preds>=0.5] = 1\n",
    "preds[preds<0.5] = 0\n",
    "# score = compare preds and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e84c54c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5c7b8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(preds[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e381f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
