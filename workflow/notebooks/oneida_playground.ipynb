{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "60a311bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "cell": {
        "!": "OSMagics",
        "HTML": "Other",
        "SVG": "Other",
        "bash": "Other",
        "capture": "ExecutionMagics",
        "debug": "ExecutionMagics",
        "file": "Other",
        "html": "DisplayMagics",
        "javascript": "DisplayMagics",
        "js": "DisplayMagics",
        "latex": "DisplayMagics",
        "markdown": "DisplayMagics",
        "perl": "Other",
        "prun": "ExecutionMagics",
        "pypy": "Other",
        "python": "Other",
        "python2": "Other",
        "python3": "Other",
        "ruby": "Other",
        "script": "ScriptMagics",
        "sh": "Other",
        "svg": "DisplayMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "writefile": "OSMagics"
       },
       "line": {
        "alias": "OSMagics",
        "alias_magic": "BasicMagics",
        "autoawait": "AsyncMagics",
        "autocall": "AutoMagics",
        "automagic": "AutoMagics",
        "autosave": "KernelMagics",
        "bookmark": "OSMagics",
        "cat": "Other",
        "cd": "OSMagics",
        "clear": "KernelMagics",
        "colors": "BasicMagics",
        "conda": "PackagingMagics",
        "config": "ConfigMagics",
        "connect_info": "KernelMagics",
        "cp": "Other",
        "debug": "ExecutionMagics",
        "dhist": "OSMagics",
        "dirs": "OSMagics",
        "doctest_mode": "BasicMagics",
        "ed": "Other",
        "edit": "KernelMagics",
        "env": "OSMagics",
        "gui": "BasicMagics",
        "hist": "Other",
        "history": "HistoryMagics",
        "killbgscripts": "ScriptMagics",
        "ldir": "Other",
        "less": "KernelMagics",
        "lf": "Other",
        "lk": "Other",
        "ll": "Other",
        "load": "CodeMagics",
        "load_ext": "ExtensionMagics",
        "loadpy": "CodeMagics",
        "logoff": "LoggingMagics",
        "logon": "LoggingMagics",
        "logstart": "LoggingMagics",
        "logstate": "LoggingMagics",
        "logstop": "LoggingMagics",
        "ls": "Other",
        "lsmagic": "BasicMagics",
        "lx": "Other",
        "macro": "ExecutionMagics",
        "magic": "BasicMagics",
        "man": "KernelMagics",
        "matplotlib": "PylabMagics",
        "mkdir": "Other",
        "more": "KernelMagics",
        "mv": "Other",
        "notebook": "BasicMagics",
        "page": "BasicMagics",
        "pastebin": "CodeMagics",
        "pdb": "ExecutionMagics",
        "pdef": "NamespaceMagics",
        "pdoc": "NamespaceMagics",
        "pfile": "NamespaceMagics",
        "pinfo": "NamespaceMagics",
        "pinfo2": "NamespaceMagics",
        "pip": "PackagingMagics",
        "popd": "OSMagics",
        "pprint": "BasicMagics",
        "precision": "BasicMagics",
        "prun": "ExecutionMagics",
        "psearch": "NamespaceMagics",
        "psource": "NamespaceMagics",
        "pushd": "OSMagics",
        "pwd": "OSMagics",
        "pycat": "OSMagics",
        "pylab": "PylabMagics",
        "qtconsole": "KernelMagics",
        "quickref": "BasicMagics",
        "recall": "HistoryMagics",
        "rehashx": "OSMagics",
        "reload_ext": "ExtensionMagics",
        "rep": "Other",
        "rerun": "HistoryMagics",
        "reset": "NamespaceMagics",
        "reset_selective": "NamespaceMagics",
        "rm": "Other",
        "rmdir": "Other",
        "run": "ExecutionMagics",
        "save": "CodeMagics",
        "sc": "OSMagics",
        "set_env": "OSMagics",
        "store": "StoreMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "tb": "ExecutionMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "unalias": "OSMagics",
        "unload_ext": "ExtensionMagics",
        "who": "NamespaceMagics",
        "who_ls": "NamespaceMagics",
        "whos": "NamespaceMagics",
        "xdel": "NamespaceMagics",
        "xmode": "BasicMagics"
       }
      },
      "text/plain": [
       "Available line magics:\n",
       "%alias  %alias_magic  %autoawait  %autocall  %automagic  %autosave  %bookmark  %cat  %cd  %clear  %colors  %conda  %config  %connect_info  %cp  %debug  %dhist  %dirs  %doctest_mode  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %lf  %lk  %ll  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %lx  %macro  %magic  %man  %matplotlib  %mkdir  %more  %mv  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %pip  %popd  %pprint  %precision  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %rep  %rerun  %reset  %reset_selective  %rm  %rmdir  %run  %save  %sc  %set_env  %store  %sx  %system  %tb  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %xmode\n",
       "\n",
       "Available cell magics:\n",
       "%%!  %%HTML  %%SVG  %%bash  %%capture  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%markdown  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n",
       "\n",
       "Automagic is ON, % prefix IS NOT needed for line magics."
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ed461e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Author: M Arshad Zahangir Chowdhury\n",
    "Email: arshad.zahangir.bd[at]gmail[dot]com\n",
    "Definitions of various models tested for voc-net.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns  #heat map\n",
    "import glob # batch processing of images\n",
    "\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "from datetime import date, datetime\n",
    "from tempfile import TemporaryFile\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix    #confusion matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Collect all the font names available to matplotlib\n",
    "font_names = [f.name for f in fm.fontManager.ttflist]\n",
    "# print(font_names)\n",
    "\n",
    "from scipy import signal\n",
    "from scipy import interpolate\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "#Sklearn model saving and loading\n",
    "from joblib import dump, load\n",
    "\n",
    "if '../../' not in sys.path:\n",
    "    sys.path.append('../../')\n",
    "\n",
    "from aimos.spectral_datasets.THz_datasets import THz_data\n",
    "from aimos.misc.utils import simple_plotter\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class THz_mixture_data:\n",
    "    '''\n",
    "    \n",
    "    A class to create mixture data using the THz dataset at 0.016 wavenumber resolution.\n",
    "    basis attribute contains the pure spectra.\n",
    "    \n",
    "    resolution : float, 0.016, 0.001, 0.0001, 0.00004 1/cm are available resolutions\n",
    "    verbosity : boolean, to get description\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, resolution = 0.016, pressure = '1 Torr', verbosity = False):\n",
    "        self.resolution = resolution\n",
    "        self.pressure = pressure\n",
    "        self.labels = ['CH3Cl', 'CH3OH', 'HCOOH', 'H2CO', 'H2S', 'SO2','OCS','HCN','CH3CN','HNO3','C2H5OH','CH3CHO']\n",
    "        self.label_id = np.array([0,1,2,3,4,5,6,7,8,9,10,11]) \n",
    "        self.n_compounds=12 # total no. of compounds\n",
    "        self.n_spectrum=164 # total no. of individual spectrum for a single compound\n",
    "        self.n_spectra = self.n_spectrum*self.n_compounds\n",
    "        \n",
    "        self.n_mixture_component_max = 12\n",
    "\n",
    "        self.components = np.array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,12]]) # extra 1 is for diluent\n",
    "        \n",
    "\n",
    "        \n",
    "        self.verbosity = verbosity\n",
    "    \n",
    "\n",
    "    def initiate_THz_mixture_data(self, TAAT, ASAT, RSAT) :\n",
    "        print('Components : ',self.components)\n",
    "        print('Components shape : ',self.components.shape)\n",
    "        \n",
    "        # load THz data and filter it at the index corresponding to 1 Torr pressure\n",
    "        \n",
    "        s = THz_data(resolution=self.resolution, verbosity=self.verbosity)\n",
    "        s.load_THz_data()\n",
    "        \n",
    "        self.frequencies= s.frequencies\n",
    "        self.n_compounds=12\n",
    "        self.TAAT = TAAT\n",
    "        self.ASAT = ASAT\n",
    "        self.RSAT = RSAT\n",
    "        \n",
    "        print('TAAT = ', self.TAAT)\n",
    "        print('ASAT = ', self.ASAT)\n",
    "        print('RSAT = ', self.RSAT)\n",
    "        \n",
    "        if self.pressure == '1 Torr':\n",
    "            s.filter_by_index(6,7)\n",
    "            \n",
    "        elif self.pressure == '2 Torr':\n",
    "            s.filter_by_index(16,17)\n",
    "        \n",
    "        elif self.pressure == '3 Torr':\n",
    "            s.filter_by_index(26,27)\n",
    "        \n",
    "        elif self.pressure == '4 Torr':\n",
    "            s.filter_by_index(36,37)\n",
    "        \n",
    "        elif self.pressure == '5 Torr':\n",
    "            s.filter_by_index(46,47)\n",
    "        \n",
    "        elif self.pressure == '6 Torr':\n",
    "            s.filter_by_index(56,57)\n",
    "        \n",
    "        elif self.pressure == '7 Torr':\n",
    "            s.filter_by_index(66,67)\n",
    "        \n",
    "        elif self.pressure == '8 Torr':\n",
    "            s.filter_by_index(76,77)\n",
    "        \n",
    "        elif self.pressure == '9 Torr':\n",
    "            s.filter_by_index(86,87)\n",
    "        \n",
    "        elif self.pressure == '10 Torr':\n",
    "            s.filter_by_index(96,97)\n",
    "            \n",
    "        elif self.pressure == '11 Torr':\n",
    "            s.filter_by_index(106,107)\n",
    "            \n",
    "        elif self.pressure == '12 Torr':\n",
    "            s.filter_by_index(116,117)\n",
    "        \n",
    "        elif self.pressure == '13 Torr':\n",
    "            s.filter_by_index(126,127)\n",
    "        \n",
    "        elif self.pressure == '14 Torr':\n",
    "            s.filter_by_index(136,137)\n",
    "        \n",
    "        elif self.pressure == '15 Torr':\n",
    "            s.filter_by_index(146,147)\n",
    "            \n",
    "        elif self.pressure == '16 Torr':\n",
    "            s.filter_by_index(156,157)\n",
    "        \n",
    "        \n",
    "\n",
    "        self.basis_C2H5OH=s.filtered_C2H5OH_spectra.reshape(s.samplesize)\n",
    "        self.basis_CH3CHO=s.filtered_CH3CHO_spectra.reshape(s.samplesize)\n",
    "        self.basis_CH3Cl=s.filtered_CH3Cl_spectra.reshape(s.samplesize)\n",
    "        self.basis_CH3CN=s.filtered_CH3CN_spectra.reshape(s.samplesize)\n",
    "        self.basis_CH3OH=s.filtered_CH3OH_spectra.reshape(s.samplesize)\n",
    "        self.basis_H2CO=s.filtered_H2CO_spectra.reshape(s.samplesize)\n",
    "        self.basis_H2S=s.filtered_H2S_spectra.reshape(s.samplesize)\n",
    "        self.basis_HCN=s.filtered_HCN_spectra.reshape(s.samplesize)\n",
    "        self.basis_HCOOH=s.filtered_HCOOH_spectra.reshape(s.samplesize)\n",
    "        self.basis_HNO3=s.filtered_HNO3_spectra.reshape(s.samplesize)\n",
    "        self.basis_OCS=s.filtered_H2S_spectra.reshape(s.samplesize)\n",
    "        self.basis_SO2=s.filtered_SO2_spectra.reshape(s.samplesize)\n",
    "        \n",
    "        self.n_features = s.samplesize\n",
    "        \n",
    "        \n",
    "        self.basis = np.array([[self.basis_C2H5OH], \n",
    "                  [self.basis_CH3CHO],\n",
    "                  [self.basis_CH3Cl],\n",
    "                  [self.basis_CH3CN],\n",
    "                  [self.basis_CH3OH],\n",
    "                  [self.basis_H2CO],\n",
    "                  [self.basis_H2S],\n",
    "                  [self.basis_HCN],\n",
    "                  [self.basis_HCOOH],\n",
    "                  [self.basis_HNO3],\n",
    "                  [self.basis_OCS],\n",
    "                  [self.basis_SO2]                  \n",
    "                 ])\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.basis=self.basis.reshape(self.n_compounds, self.n_features)\n",
    "        \n",
    "        self.labels = [' ', '', 'Diluent' ,r'$C_2H_5OH$', r'$CH_3CHO$', r'$CH_3Cl$', \n",
    "                       r'$CH_3CN$', r'$CH_3OH$', r'$H_2CO$', r'$H_2S$', r'$HCN$',\n",
    "                       r'$HCOOH$', r'$HNO_3$', r'$OCS$', r'$SO_2$']\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.verbosity == True:\n",
    "        \n",
    "            print('labels : ', self.labels)\n",
    "            print('Basis shape:',self.basis.shape)\n",
    "        \n",
    "        \n",
    "    def make_pure_mixture(self, n_mixture_pure):\n",
    "        \n",
    "        '''\n",
    "        adds a fixed number for each of the random pure component mixtures.\n",
    "        \n",
    "        n_mixture_pure: int, number of total pure mixtures \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        self.n_mixture_pure=n_mixture_pure\n",
    "\n",
    "        targets_c1 = np.empty((self.n_mixture_pure,self.n_mixture_component_max),dtype=object)\n",
    "        dilution_c1 = np.empty((self.n_mixture_pure),dtype=object)\n",
    "\n",
    "        targets_c2 = np.empty((self.n_mixture_pure,self.n_mixture_component_max),dtype=object)\n",
    "        dilution_c2 = np.empty((self.n_mixture_pure),dtype=object)\n",
    "\n",
    "        targets_c3 = np.empty((self.n_mixture_pure,self.n_mixture_component_max),dtype=object)\n",
    "        dilution_c3 = np.empty((self.n_mixture_pure),dtype=object)\n",
    "\n",
    "        targets_c4 = np.empty((self.n_mixture_pure,self.n_mixture_component_max),dtype=object)\n",
    "        dilution_c4 = np.empty((self.n_mixture_pure),dtype=object)\n",
    "\n",
    "        targets_c5 = np.empty((self.n_mixture_pure,self.n_mixture_component_max),dtype=object)\n",
    "        dilution_c5 = np.empty((self.n_mixture_pure),dtype=object)\n",
    "\n",
    "        targets_c6 = np.empty((self.n_mixture_pure,self.n_mixture_component_max),dtype=object)\n",
    "        dilution_c6 = np.empty((self.n_mixture_pure),dtype=object)\n",
    "\n",
    "        targets_c7 = np.empty((self.n_mixture_pure,self.n_mixture_component_max),dtype=object)\n",
    "        dilution_c7 = np.empty((self.n_mixture_pure),dtype=object)\n",
    "\n",
    "        targets_c8 = np.empty((self.n_mixture_pure,self.n_mixture_component_max),dtype=object)\n",
    "        dilution_c8 = np.empty((self.n_mixture_pure),dtype=object)\n",
    "\n",
    "        targets_c9 = np.empty((self.n_mixture_pure,self.n_mixture_component_max),dtype=object)\n",
    "        dilution_c9 = np.empty((self.n_mixture_pure),dtype=object)\n",
    "\n",
    "        targets_c10 = np.empty((self.n_mixture_pure,self.n_mixture_component_max),dtype=object)\n",
    "        dilution_c10 = np.empty((self.n_mixture_pure),dtype=object)\n",
    "\n",
    "        targets_c11 = np.empty((self.n_mixture_pure,self.n_mixture_component_max),dtype=object)\n",
    "        dilution_c11 = np.empty((self.n_mixture_pure),dtype=object)\n",
    "\n",
    "        targets_c12 = np.empty((self.n_mixture_pure,self.n_mixture_component_max),dtype=object)\n",
    "        dilution_c12 = np.empty((self.n_mixture_pure),dtype=object)\n",
    "\n",
    "        mixtures_c1 = np.empty((self.n_mixture_pure,1, self.n_features),dtype=object)\n",
    "        mixtures_c2 = np.empty((self.n_mixture_pure,1, self.n_features),dtype=object)\n",
    "        mixtures_c3 = np.empty((self.n_mixture_pure,1, self.n_features),dtype=object)\n",
    "        mixtures_c4 = np.empty((self.n_mixture_pure,1, self.n_features),dtype=object)\n",
    "\n",
    "        mixtures_c5 = np.empty((self.n_mixture_pure,1, self.n_features),dtype=object)\n",
    "        mixtures_c6 = np.empty((self.n_mixture_pure,1, self.n_features),dtype=object)\n",
    "        mixtures_c7 = np.empty((self.n_mixture_pure,1, self.n_features),dtype=object)\n",
    "        mixtures_c8 = np.empty((self.n_mixture_pure,1, self.n_features),dtype=object)\n",
    "\n",
    "        mixtures_c9 = np.empty((self.n_mixture_pure,1, self.n_features),dtype=object)\n",
    "        mixtures_c10 = np.empty((self.n_mixture_pure,1, self.n_features),dtype=object)\n",
    "        mixtures_c11 = np.empty((self.n_mixture_pure,1, self.n_features),dtype=object)\n",
    "        mixtures_c12 = np.empty((self.n_mixture_pure,1, self.n_features),dtype=object)\n",
    "\n",
    "        \n",
    "        c1=[1,0,0,0,0,0,0,0,0,0,0,0]\n",
    "        c2=[0,1,0,0,0,0,0,0,0,0,0,0]\n",
    "        c3=[0,0,1,0,0,0,0,0,0,0,0,0]\n",
    "        c4=[0,0,0,1,0,0,0,0,0,0,0,0]\n",
    "\n",
    "        c5=[0,0,0,0,1,0,0,0,0,0,0,0]\n",
    "        c6=[0,0,0,0,0,1,0,0,0,0,0,0]\n",
    "        c7=[0,0,0,0,0,0,1,0,0,0,0,0]\n",
    "        c8=[0,0,0,0,0,0,0,1,0,0,0,0]\n",
    "\n",
    "        c9=[0,0,0,0,0,0,0,0,1,0,0,0]\n",
    "        c10=[0,0,0,0,0,0,0,0,0,1,0,0]\n",
    "        c11=[0,0,0,0,0,0,0,0,0,0,1,0]\n",
    "        c12=[0,0,0,0,0,0,0,0,0,0,0,1]\n",
    "\n",
    "        for j in range(self.n_mixture_pure):\n",
    "            dilution_c1[j]=np.random.random(1)\n",
    "\n",
    "            targets_c1[j] = (1-dilution_c1[j])*c1\n",
    "            targets_c1[j]=targets_c1[j].astype(np.float64)\n",
    "            mixtures_c1[j] = np.dot(self.basis.T,targets_c1[j])\n",
    "\n",
    "\n",
    "            dilution_c2[j]=np.random.random(1)\n",
    "\n",
    "            targets_c2[j] = (1-dilution_c2[j])*c2\n",
    "            targets_c2[j]=targets_c2[j].astype(np.float64)\n",
    "            mixtures_c2[j] = np.dot(self.basis.T,targets_c2[j])\n",
    "\n",
    "            dilution_c3[j]=np.random.random(1)\n",
    "\n",
    "            targets_c3[j] = (1-dilution_c3[j])*c3\n",
    "            targets_c3[j]=targets_c3[j].astype(np.float64)\n",
    "            mixtures_c3[j] = np.dot(self.basis.T,targets_c3[j])\n",
    "\n",
    "            dilution_c4[j]=np.random.random(1)\n",
    "\n",
    "            targets_c4[j] = (1-dilution_c4[j])*c4\n",
    "            targets_c4[j]=targets_c4[j].astype(np.float64)\n",
    "            mixtures_c4[j] = np.dot(self.basis.T,targets_c4[j])\n",
    "\n",
    "            dilution_c5[j]=np.random.random(1)\n",
    "\n",
    "            targets_c5[j] = (1-dilution_c5[j])*c5\n",
    "            targets_c5[j]=targets_c5[j].astype(np.float64)\n",
    "            mixtures_c5[j] = np.dot(self.basis.T,targets_c5[j])\n",
    "            \n",
    "            dilution_c6[j]=np.random.random(1)\n",
    "\n",
    "            targets_c6[j] = (1-dilution_c6[j])*c6\n",
    "            targets_c6[j]=targets_c6[j].astype(np.float)\n",
    "            mixtures_c6[j] = np.dot(self.basis.T,targets_c6[j])\n",
    "\n",
    "            dilution_c7[j]=np.random.random(1)\n",
    "\n",
    "            targets_c7[j] = (1-dilution_c7[j])*c7\n",
    "            targets_c7[j]=targets_c7[j].astype(np.float)\n",
    "            mixtures_c7[j] = np.dot(self.basis.T,targets_c7[j])\n",
    "\n",
    "            dilution_c8[j]=np.random.random(1)\n",
    "\n",
    "            targets_c8[j] = (1-dilution_c8[j])*c8\n",
    "            targets_c8[j]=targets_c8[j].astype(np.float)\n",
    "            mixtures_c8[j] = np.dot(self.basis.T,targets_c8[j])\n",
    "\n",
    "            dilution_c9[j]=np.random.random(1)\n",
    "\n",
    "            targets_c9[j] = (1-dilution_c9[j])*c9\n",
    "            targets_c9[j]=targets_c9[j].astype(np.float)\n",
    "            mixtures_c9[j] = np.dot(self.basis.T,targets_c9[j])\n",
    "\n",
    "            dilution_c10[j]=np.random.random(1)\n",
    "\n",
    "            targets_c10[j] = (1-dilution_c10[j])*c10\n",
    "            targets_c10[j]=targets_c10[j].astype(np.float)\n",
    "            mixtures_c10[j] = np.dot(self.basis.T,targets_c10[j])\n",
    "\n",
    "            dilution_c11[j]=np.random.random(1)\n",
    "\n",
    "            targets_c11[j] = (1-dilution_c11[j])*c11\n",
    "            targets_c11[j]=targets_c11[j].astype(np.float)\n",
    "            mixtures_c11[j] = np.dot(self.basis.T,targets_c11[j])\n",
    "\n",
    "            dilution_c12[j]=np.random.random(1)\n",
    "\n",
    "            targets_c12[j] = (1-dilution_c12[j])*c12\n",
    "            targets_c12[j]=targets_c12[j].astype(np.float)\n",
    "            mixtures_c12[j] = np.dot(self.basis.T,targets_c12[j])\n",
    "\n",
    "\n",
    "    \n",
    "            #Add all pure mixtures together\n",
    "\n",
    "            targets_pure=np.concatenate((targets_c1,targets_c2,targets_c3,targets_c4,\n",
    "                                          targets_c5,targets_c6,targets_c7,targets_c8,\n",
    "                                          targets_c9,targets_c10,targets_c11,targets_c12),axis=0)\n",
    "\n",
    "            mixtures_pure=np.concatenate((mixtures_c1,mixtures_c2,mixtures_c3,mixtures_c4,\n",
    "                                          mixtures_c5,mixtures_c6,mixtures_c7,mixtures_c8,\n",
    "                                          mixtures_c9,mixtures_c10,mixtures_c11,mixtures_c12),axis=0)\n",
    "\n",
    "            self.targets_pure=targets_pure.astype(np.float64)\n",
    "            self.mixtures_pure=mixtures_pure.astype(np.float64)\n",
    "            \n",
    "        if self.verbosity == True:\n",
    "\n",
    "            print('targets_pure data type: ', self.targets_pure.dtype)\n",
    "            print('mixtures_pure data type: ', self.mixtures_pure.dtype)\n",
    "\n",
    "\n",
    "            print('targets_pure.shape :',self.targets_pure.shape)\n",
    "            print('mixtures_pure.shape :',self.mixtures_pure.shape)\n",
    "            \n",
    "            \n",
    "    def make_artificial_mixtures(self,n_mixtures):\n",
    "        # Number of artificial randomized mixtures\n",
    "        # This should equal to predetermined array size and loop counter\n",
    "\n",
    "        # Have to set a random number seed here\n",
    "\n",
    "        \n",
    "        t_start = datetime.now()\n",
    "\n",
    "        self.n_mixtures = n_mixtures\n",
    "\n",
    "        targets = np.empty((self.n_mixtures,self.n_mixture_component_max),dtype=object)\n",
    "        dilution = np.empty((self.n_mixtures),dtype=object)\n",
    "        for i in range(self.n_mixtures):\n",
    "        #      a[x]=np.array([x, x+1])\n",
    "                c_rand=np.random.random(12)\n",
    "                c_rand /=c_rand.sum()\n",
    "                dilution[i]=np.random.random(1)\n",
    "        #         print('Dilution : ', dilution[i])\n",
    "\n",
    "                targets[i] = c_rand*(1-dilution[i])\n",
    "                targets[i]=targets[i].astype(np.float64)\n",
    "        #         print('Sum of mixture components : ', targets[i].sum())\n",
    "\n",
    "\n",
    "\n",
    "        t_end = datetime.now()\n",
    "        delta = t_end - t_start\n",
    "        Time_OVR=delta.total_seconds() * 1000\n",
    "\n",
    "        if self.verbosity == True:\n",
    "            \n",
    "            print('Time elaspsed in generating targets: ', Time_OVR) # milliseconds\n",
    "            print('Number of artificial mixtures : ', self.n_mixtures)\n",
    "            print('Targets data type: ', targets.dtype)\n",
    "            print('Targets shape: ', targets.shape)\n",
    "\n",
    "        \n",
    "        t_start = datetime.now()\n",
    "\n",
    "        mixtures = np.empty((self.n_mixtures,1, self.n_features),dtype=object)\n",
    "\n",
    "        for i in range(n_mixtures):\n",
    "            mixtures[i] = np.dot(self.basis.T,targets[i])\n",
    "            mixtures[i]=mixtures[i].astype(np.float64)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # apply thresholds here\n",
    "            if np.amax(mixtures[i]) > 0.5:\n",
    "                print('triggered')\n",
    "            \n",
    "            ######\n",
    "\n",
    "\n",
    "        t_end = datetime.now()\n",
    "        delta = t_end - t_start\n",
    "        Time_OVR=delta.total_seconds() * 1000\n",
    "        \n",
    "        if self.verbosity == True:\n",
    "            print('Loading time: ', Time_OVR) # milliseconds\n",
    "            \n",
    "            print('numpy state:',np.random.get_state()[1][0])\n",
    "\n",
    "            print('mixtures data type: ', mixtures.dtype)\n",
    "            print('mixtures shape: ', mixtures.shape)\n",
    "\n",
    "            \n",
    "        #Combine pure compounds and artificial mixtures together\n",
    "\n",
    "        #If do not want pure spectra then do not run this cell\n",
    "\n",
    "        self.n_mixtures = (self.n_mixtures + self.n_mixture_pure*self.n_mixture_component_max)\n",
    "        \n",
    "\n",
    "        self.targets=np.concatenate((self.targets_pure, targets),axis=0)\n",
    "\n",
    "        self.mixtures=np.concatenate((self.mixtures_pure, mixtures),axis=0)\n",
    "\n",
    "        \n",
    "        if self.verbosity == True:\n",
    "            print('Total number of linear simulated mixtures : ',self.n_mixtures)\n",
    "            print('\\nCombined (pure compounds and simulated mixtures)\\n')\n",
    "            print('targets data type: ', self.targets.dtype)\n",
    "            print('mixtures_pure data type: ', self.mixtures.dtype)\n",
    "            print('targets data shape: ', self.targets.shape)\n",
    "            print('mixtures_pure data shape: ', self.mixtures.shape)\n",
    "\n",
    "    def save_linear_sim_mixtures(self):\n",
    "        #save the data in binary numpy file before removing indices\n",
    "        #Get Current date and time to store the data\n",
    "\n",
    "\n",
    "        today = date.today()\n",
    "        self.now = datetime.now()\n",
    "        \n",
    "        \n",
    "\n",
    "        print(\"now =\", self.now)\n",
    "        # dd/mm/YY H:M:S\n",
    "        dt_string = self.now.strftime(\"%d-%m-%Y_time_%H-%M-%S\")\n",
    "        print(\"date and time =\", dt_string)\t\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        data_identifier = 'RandomTrainingMixtures' + '/' + 'N_mix = ' + str(self.n_mixtures) + '_' + dt_string + '_FullSet_'\n",
    "\n",
    "\n",
    "        np.save(data_identifier + 'Mixture_Net_data_mixtures', self.mixtures)\n",
    "        np.save(data_identifier + 'Mixture_Net_data_targets', self.targets)\n",
    "        \n",
    "    def apply_abs_threshold(self, Abs_threshold = 0.001 ):\n",
    "        # Check mixture threshold and eliminate\n",
    "        # mixtures[0]\n",
    "        # print the max absorbance values for all the mixtures below threshold and their indices\n",
    "        self.Abs_threshold = Abs_threshold\n",
    "        remove_indices = np.array([])\n",
    "        for _ in range(self.n_mixtures):\n",
    "            if np.amax(self.mixtures[_]) < self.Abs_threshold:\n",
    "\n",
    "        #         print('Index : ',_)\n",
    "                remove_indices=np.append(remove_indices, _)\n",
    "                #save indices in array\n",
    "        #         print(' Max Abs:',np.amax(mixtures[_]))\n",
    "\n",
    "        # print(remove_indices)\n",
    "#         print('Total indices removed : ',remove_indices)\n",
    "\n",
    "\n",
    "        if not remove_indices:\n",
    "            print(\"\\nNo spectra below threshold.\")\n",
    "        else:\n",
    "            print(\"\\nSpectra below threshold removed.\")\n",
    "            self.remove_indices=remove_indices.astype(int)\n",
    "\n",
    "        #remove those mixtures and their corresponding concentrations from dataset\n",
    "        self.mixtures=np.delete(self.mixtures, self.remove_indices, 0)\n",
    "        self.targets=np.delete(self.targets, self.remove_indices, 0)\n",
    "\n",
    "        print('mixtures data type: ', self.mixtures.dtype)\n",
    "        print('mixtures shape: ', self.mixtures.shape)\n",
    "\n",
    "        print('targets data type: ', self.targets.dtype)\n",
    "        print('targets shape: ', self.targets.shape)\n",
    "        \n",
    "        self.n_mixtures = self.n_mixtures -self.remove_indices.shape[0]\n",
    "        \n",
    "        self.mixtures = self.mixtures.reshape(self.n_mixtures,self.n_features)\n",
    "        \n",
    "    def save_thresholded_mixtures(self):        \n",
    "        #save the data in binary numpy file\n",
    "        #Get Current date and time to store the data\n",
    "        \n",
    "\n",
    "        today = date.today()\n",
    "        # now = datetime.now() # use same timestamp as before\n",
    "\n",
    "        print(\"now =\", self.now)\n",
    "        # dd/mm/YY H:M:S\n",
    "        dt_string = self.now.strftime(\"%d-%m-%Y_time_%H-%M-%S\")\n",
    "        print(\"date and time =\", dt_string)\t\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        data_identifier = 'RandomTrainingMixtures' + '/' + 'N_mix = ' + str(self.n_mixtures -self.remove_indices.shape[0]) + '_' + dt_string + '_'\n",
    "        \n",
    "\n",
    "        np.save(data_identifier + 'Mixture_Net_data_mixtures', self.mixtures)\n",
    "        np.save(data_identifier + 'Mixture_Net_data_targets', self.targets)\n",
    "        \n",
    "        \n",
    "    def _target_generator(self,n_sample_mixtures,exclude_indices, verbose=False):\n",
    "        '''Randomly generate concentration target vector with specific indices removed to come up with 2-,3-,4-\n",
    "\n",
    "        etc. component mixture\n",
    "\n",
    "        V18 added a c+ncr(n_compounds,6) +ncr(n_compounds,7) +ncr(n_compounds,8) +ncr(n_compounds,9) +ncr(n_compounds,10) +ncr(n_compounds,11) +ncr(n_compounds,12)heck so very weak component contribution spectra are taken out.\n",
    "        '''\n",
    "        t_start = datetime.now()\n",
    "        print(f'\\n ...generating {self.n_mixture_component_max-exclude_indices}-component mixtures data...\\n')\n",
    "        test_targets = np.empty((n_sample_mixtures,self.n_mixture_component_max),dtype=object)\n",
    "        test_dilution = np.empty((n_sample_mixtures),dtype=object)\n",
    "        temp_mixture = np.empty((1,1, self.n_features),dtype=object)\n",
    "        \n",
    "        i = 0\n",
    "        total_attempts = 0\n",
    "        while (i<n_sample_mixtures):\n",
    "                #reset threshold checks\n",
    "                TAAT_cond = False\n",
    "                ASAT_cond = False\n",
    "                RSAT_cond = False\n",
    "#         for i in range(n_sample_mixtures):\n",
    "        #      a[x]=np.array([x, x+1])\n",
    "                c_rand=np.random.random(self.n_mixture_component_max)\n",
    "                exclude_set_indices=random.sample(range(0, self.n_mixture_component_max), exclude_indices)\n",
    "    #             print(exclude_set_indices)\n",
    "                for _ in exclude_set_indices:\n",
    "        ##             print(_)\n",
    "                    c_rand[_]=0\n",
    "\n",
    "        ##         print('before normalization c_rand = ', c_rand)\n",
    "                c_rand /=c_rand.sum()\n",
    "        ##         print('after normalization c_rand = ', c_rand)\n",
    "                test_dilution[i]=np.random.random(1)\n",
    "                test_dilution[i]=test_dilution[i].astype(np.float64)\n",
    "    #             print('Dilution : ', test_dilution[i])\n",
    "\n",
    "                test_targets[i] = c_rand*(1-test_dilution[i])\n",
    "    #             print('\\n')\n",
    "                if verbose==True:\n",
    "                    print('test_targets = ', test_targets[i])\n",
    "    #             print('\\n')\n",
    "                test_targets[i]=test_targets[i].astype(np.float64)\n",
    "    #             print('Sum of mixture components : ', test_targets[i].sum())\n",
    "                temp_mixture = np.dot(self.basis.T.reshape(self.n_features,self.n_mixture_component_max),test_targets[i])\n",
    "                TAAT_calculated = np.amax(temp_mixture)\n",
    "#                 print(TAAT_calculated)\n",
    "                \n",
    "                \n",
    "                ASAT_calculated = [np.amax(np.dot(self.basis[lc], test_targets[i][lc])) for lc in range(0, self.n_mixture_component_max)]\n",
    "#                 print(f'ASAT_list: {ASAT_calculated}' )ASAT=0.01\n",
    "                \n",
    "                species_max_abs_contribution = [np.amax(np.dot(self.basis[lc], test_targets[i][lc])) for lc in range(self.n_mixture_component_max)]\n",
    "                strongest_absorber_abs = max(species_max_abs_contribution)\n",
    "        \n",
    "            \n",
    "                \n",
    "                \n",
    "#                 print(strongest_absorber_abs)\n",
    "\n",
    "                RSAT_calculated = [np.amax(np.dot(self.basis[lc],test_targets[i][lc])/strongest_absorber_abs) for lc in range(0, self.n_mixture_component_max)]\n",
    "    \n",
    "                \n",
    "                if TAAT_calculated > self.TAAT:\n",
    "                    TAAT_cond = True\n",
    "                    \n",
    "                if all (x > self.ASAT for x in ASAT_calculated if x>0):\n",
    "                    ASAT_cond = True\n",
    "                    \n",
    "                if all (x > self.RSAT for x in RSAT_calculated if x>0):\n",
    "                    RSAT_cond = True\n",
    "                \n",
    "                # apply the thresholds\n",
    "#                 print(f'TAAT_cond: {TAAT_cond}' )\n",
    "#                 print(f'ASAT_cond: {ASAT_cond}' )ASAT_cond\n",
    "    \n",
    "                total_attempts = total_attempts +1\n",
    "        \n",
    "                # exclude indices condition is for an exception for 12-component mixture. \n",
    "                #Remove ASAT and RSAT cod for 12-comp or reduce threshold\n",
    "                if exclude_indices != 0:\n",
    "                    if TAAT_cond:\n",
    "                        if ASAT_cond:\n",
    "                            if RSAT_cond:\n",
    "                                i=i+1\n",
    "                else:\n",
    "                    if TAAT_cond:\n",
    "                        if ASAT_cond:\n",
    "                            if RSAT_cond:\n",
    "                                i=i+1\n",
    "                \n",
    "                \n",
    "        print(f'total_attempts: {total_attempts}' ) \n",
    "        t_end = datetime.now()\n",
    "        delta = t_end - t_start\n",
    "        Time_OVR=delta.total_seconds() * 1000\n",
    "        print('Generator Time elasped:',Time_OVR)\n",
    "        return test_targets, test_dilution\n",
    "\n",
    "    \n",
    "      \n",
    "        \n",
    "    def make_controlled_sim_mixtures(self, \n",
    "                                      equal_amount = 10000, \n",
    "                                      TAAT = 0.00001, \n",
    "                                      ASAT=0.001, \n",
    "                                      RSAT=0.01,\n",
    "                                      save_to_file = False, debug=False):\n",
    "        \n",
    "        '''\n",
    "        Creates controlled 1-, 2-, 3-, 4- , 5- 6-, 7-, 8-, 9-, 10-, 11- and 12- component test mixtures, applies absorbance threshold to remove mixtures below a certain absorbance value. The function saves 6 files. Fullset refers to mixtures created completely randomly. Absorbance thresholded mixtures do not have any other comments in the filename. \"weak_rm\" refers to the removal of spectra containing very weak contribution from at least one component species.\n",
    "        \n",
    "        \n",
    "        equal amount: int, the amount of 1-, 2-, 3-, 4- , 5- 6-, 7-, 8-, 9-, 10-, 11- component mixtures.\n",
    "        tweleve_component_amount: int, the amount of 12- component mixtures.\n",
    "        TAAT: float, an absolute absorbance threshold on the spectra itself. Any mixture with maximum absorbance below this value is excluded.\n",
    "        ASAT: float, an absolute absorbance threshold on the absorbance contribution for each individual species present in the spectra. Any mixture containing at least one such species is excluded.\n",
    "        RSAT: float, a relative absorbance threshold on the absorbance contribution for each individual species with respect to the highest individual absorber species present in the spectra. Any mixture containing at least one such species is excluded. This threshold ensures that every species is not too weak relative to the strongest absorber speices in the mixture.\n",
    "        save_to_file, boolean, saves mixture data into .npy files.\n",
    "        debug, boolean, print out each threshold values for debugging.\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        t_start = datetime.now()\n",
    "\n",
    "\n",
    "        n_test_pure_mixtures = equal_amount\n",
    "        n_test_two_component_mixtures = equal_amount\n",
    "        n_test_three_component_mixtures = equal_amount\n",
    "        n_test_four_component_mixtures = equal_amount\n",
    "        n_test_five_component_mixtures = equal_amount\n",
    "        n_test_six_component_mixtures = equal_amount\n",
    "        n_test_seven_component_mixtures = equal_amount\n",
    "        n_test_eight_component_mixtures = equal_amount\n",
    "        n_test_nine_component_mixtures = equal_amount\n",
    "        n_test_ten_component_mixtures = equal_amount\n",
    "        n_test_eleven_component_mixtures = equal_amount\n",
    "        n_test_twelve_component_mixtures = equal_amount\n",
    "        \n",
    "\n",
    "        test_targets_pure,test_targets_pure_dilution = self._target_generator(n_test_pure_mixtures,11)\n",
    "        test_targets_two_components,test_targets_two_components_dilution = self._target_generator(n_test_two_component_mixtures,10)\n",
    "        test_targets_three_components,test_targets_three_components_dilution = self._target_generator(n_test_three_component_mixtures,9)\n",
    "        test_targets_four_components,test_targets_four_components_dilution = self._target_generator(n_test_four_component_mixtures,8)\n",
    "        test_targets_five_components,test_targets_five_components_dilution = self._target_generator(n_test_five_component_mixtures,7)\n",
    "        test_targets_six_components,test_targets_six_components_dilution = self._target_generator(n_test_six_component_mixtures,6)\n",
    "        test_targets_seven_components,test_targets_seven_components_dilution = self._target_generator(n_test_seven_component_mixtures,5)\n",
    "        test_targets_eight_components,test_targets_eight_components_dilution = self._target_generator(n_test_eight_component_mixtures,4)\n",
    "        test_targets_nine_components,test_targets_nine_components_dilution = self._target_generator(n_test_nine_component_mixtures,3)\n",
    "        test_targets_ten_components,test_targets_ten_components_dilution = self._target_generator(n_test_ten_component_mixtures,2)\n",
    "        test_targets_eleven_components,test_targets_eleven_components_dilution = self._target_generator(n_test_eleven_component_mixtures,1)\n",
    "        test_targets_twelve_components,test_targets_twelve_components_dilution = self._target_generator(n_test_twelve_component_mixtures,0)\n",
    "        \n",
    "\n",
    "        t_end = datetime.now()\n",
    "        delta = t_end - t_start\n",
    "        Time_OVR=delta.total_seconds() * 1000\n",
    "        print('Time elasped:',Time_OVR)\n",
    "\n",
    "\n",
    "        #Combine all the test mixtures together\n",
    "\n",
    "        #If do not want pure spectra then do not run this cell\n",
    "\n",
    "        n_test_mixtures = (n_test_pure_mixtures + \n",
    "                           n_test_two_component_mixtures +\n",
    "                           n_test_three_component_mixtures +\n",
    "                           n_test_four_component_mixtures +\n",
    "                           n_test_five_component_mixtures +\n",
    "                           n_test_six_component_mixtures +\n",
    "                           n_test_seven_component_mixtures +\n",
    "                           n_test_eight_component_mixtures +\n",
    "                           n_test_nine_component_mixtures +\n",
    "                           n_test_ten_component_mixtures +\n",
    "                           n_test_eleven_component_mixtures +\n",
    "                           n_test_twelve_component_mixtures                  \n",
    "                          )\n",
    "        print('Total number of test mixtures : ',n_test_mixtures)\n",
    "\n",
    "        test_targets=np.concatenate((test_targets_pure, \n",
    "                                     test_targets_two_components,\n",
    "                                     test_targets_three_components,\n",
    "                                     test_targets_four_components,\n",
    "                                     test_targets_five_components,\n",
    "                                     test_targets_six_components,\n",
    "                                     test_targets_seven_components,\n",
    "                                     test_targets_eight_components,\n",
    "                                     test_targets_nine_components,\n",
    "                                     test_targets_ten_components,\n",
    "                                     test_targets_eleven_components,\n",
    "                                     test_targets_twelve_components \n",
    "                                    ),axis=0)\n",
    "\n",
    "        test_dilution=np.concatenate((test_targets_pure_dilution, \n",
    "                                     test_targets_two_components_dilution,\n",
    "                                     test_targets_three_components_dilution,\n",
    "                                     test_targets_four_components_dilution,\n",
    "                                     test_targets_five_components_dilution,\n",
    "                                     test_targets_six_components_dilution,\n",
    "                                     test_targets_seven_components_dilution,\n",
    "                                     test_targets_eight_components_dilution,\n",
    "                                     test_targets_nine_components_dilution,\n",
    "                                     test_targets_ten_components_dilution,\n",
    "                                     test_targets_eleven_components_dilution,\n",
    "                                     test_targets_twelve_components_dilution\n",
    "                                     ),axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print('\\nCombined test simulated mixtures\\n')\n",
    "\n",
    "        print('No. of test mixtures: ', n_test_mixtures)\n",
    "\n",
    "        print('test_targets data type: ', test_targets.dtype)\n",
    "        print('test_targets data shape: ', test_targets.shape)\n",
    "\n",
    "\n",
    "\n",
    "        t_start = datetime.now()\n",
    "\n",
    "        test_mixtures = np.empty((n_test_mixtures,1, self.n_features),dtype=object)\n",
    "        \n",
    "        \n",
    "        print('Generating mixtures with TAAT')\n",
    "\n",
    "        for j in tqdm(range(n_test_mixtures)):\n",
    "            test_mixtures[j] = np.dot(self.basis.T.reshape(self.n_features,self.n_mixture_component_max),test_targets[j])\n",
    "            test_mixtures[j]=test_mixtures[j].astype(np.float64)\n",
    "            \n",
    "            # apply thresholds here\n",
    "#             if np.amax(test_mixtures[j]) < 0.5:\n",
    "#                 print('triggered')\n",
    "            \n",
    "            ######\n",
    "        #     print(test_mixtures[j])\n",
    "\n",
    "\n",
    "        t_end = datetime.now()\n",
    "        delta = t_end - t_start\n",
    "        Time_OVR=delta.total_seconds() * 1000\n",
    "\n",
    "        print('Time elaspsed: ', Time_OVR) # milliseconds\n",
    "\n",
    "        # Use predetermined mixtures to understand the model better\n",
    "        #Print the random number seed\n",
    "        print('numpy random state: ', np.random.get_state()[1][0])\n",
    "\n",
    "                \n",
    "        self.n_test_mixtures = n_test_mixtures\n",
    "        self.test_targets = test_targets\n",
    "        self.test_dilution = test_dilution\n",
    "        self.test_mixtures = test_mixtures\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        if save_to_file == True:\n",
    "        \n",
    "            print('test mixtures data type: ', self.test_mixtures.dtype)\n",
    "            print('test mixtures shape: ', self.test_mixtures.shape)\n",
    "\n",
    "            today = date.today()\n",
    "            now = datetime.now()\n",
    "\n",
    "            print(\"now =\", now)\n",
    "            # dd/mm/YY H:M:S\n",
    "            dt_string = now.strftime(\"%d-%m-%Y_time_%H-%M-%S\")\n",
    "            print(\"date and time =\", dt_string)\t\n",
    "\n",
    "            data_identifier = 'datasets' + '/' + 'N_mix = ' + str(self.n_test_mixtures) + '_' + dt_string + '_FullSet_'\n",
    "\n",
    "            np.save(data_identifier + 'TSMC_Net_data_test_mixtures', self.test_mixtures)\n",
    "            np.save(data_identifier + 'TSMC_Net_data_test_targets', self.test_targets)\n",
    "            \n",
    "        # start removing indices based on total absolute absorbance threshold on mixture spectra\n",
    "        print('\\nreimplementing TAAT')\n",
    "        \n",
    "        t_start = datetime.now()\n",
    "        \n",
    "        remove_indices = np.array([])\n",
    "        for _ in tqdm(range(self.n_test_mixtures)) :\n",
    "            TAAT_calculated = np.amax(self.test_mixtures[_])\n",
    "            if TAAT_calculated < TAAT:\n",
    "                if debug == True:\n",
    "                    print(f'species id: {self.labels[_]} TAAT_calc = {TAAT_calculated}    TAAT = {TAAT}')\n",
    "                    \n",
    "\n",
    "        #         print('Index : ',_)\n",
    "                remove_indices=np.append(remove_indices, _)\n",
    "                #save indices in array\n",
    "        #         print(' Max Abs:',np.amax(mixtures[_]))\n",
    "\n",
    "        # print(Remove_indices)\n",
    "#         print('Total indices removed : ',remove_indices)\n",
    "        remove_indices=remove_indices.astype(int)\n",
    "        \n",
    "        \n",
    "        #remove those mixtures and their corresponding concentrations from dataset\n",
    "        self.test_mixtures=np.delete(self.test_mixtures, remove_indices, 0)\n",
    "        self.test_targets=np.delete(self.test_targets, remove_indices, 0)\n",
    "        print('Total spectra with weak mixture spectra:',np.unique(remove_indices).shape)    \n",
    "\n",
    "        print('test_mixtures data type: ', self.test_mixtures.dtype)\n",
    "        print('test_mixtures shape: ', self.test_mixtures.shape)\n",
    "\n",
    "        print('test_targets data type: ', self.test_targets.dtype)\n",
    "        print('test_targets shape: ', self.test_targets.shape)\n",
    "        \n",
    "        \n",
    "        #Adjust the number of test mixtures\n",
    "        \n",
    "        self.n_test_mixtures = self.n_test_mixtures - remove_indices.shape[0]\n",
    "        print('Adjusted n_test_mixtures: ', self.n_test_mixtures)\n",
    "        \n",
    "        \n",
    "        t_end = datetime.now()\n",
    "        delta = t_end - t_start\n",
    "        Time_OVR=delta.total_seconds() * 1000\n",
    "        print('TAAT Time elasped:',Time_OVR)\n",
    "        \n",
    "        if save_to_file == True:\n",
    "        \n",
    "            today = date.today()\n",
    "            now = datetime.now()\n",
    "\n",
    "            print(\"now =\", now)\n",
    "            # dd/mm/YY H:M:S\n",
    "            dt_string = now.strftime(\"%d-%m-%Y_time_%H-%M-%S\")\n",
    "            print(\"date and time =\", dt_string)\t\n",
    "\n",
    "            data_identifier = 'datasets' + '/' + 'N_mix = ' + str(self.n_test_mixtures) + '_' + dt_string + '_'\n",
    "\n",
    "            np.save(data_identifier + 'TSMC_Net_data_test_mixtures', self.test_mixtures)\n",
    "            np.save(data_identifier + 'TSMC_Net_data_test_targets', self.test_targets)\n",
    "        \n",
    "        \n",
    "        #integrate the stricter species wise detection threshold (absolute)\n",
    "        \n",
    "        \n",
    "        \n",
    "        print('reimplementing ASAT')\n",
    "        t_start = datetime.now()\n",
    "        remove_indices = np.array([])\n",
    "        # for i in range(y_test.shape[0]):\n",
    "        for i in tqdm(range(self.n_test_mixtures)):\n",
    "        #     print(i)\n",
    "            for _ in range(self.n_mixture_component_max):\n",
    "                ASAT_calculated = np.amax(np.dot(self.basis[_],self.test_targets[i][_]))\n",
    "                if ASAT_calculated < ASAT and ASAT_calculated > 0:\n",
    "                    if debug == True:\n",
    "                        print(f'species id: {self.labels[_]} ASAT_calc = {ASAT_calculated}    ASAT = {ASAT}')\n",
    "                    remove_indices=np.append(remove_indices, i)\n",
    "                    break\n",
    "                    \n",
    "        #             print( np.amax(np.dot(Basis[_],y_test[i][_])) )\n",
    "        #             print(i)\n",
    "        # Remove this indice spectra from y_test_BK and X_test_BK         \n",
    "\n",
    "        #         print( np.dot(Basis[_],y_test[i][_]).shape )\n",
    "\n",
    "        remove_indices=np.unique(remove_indices) #Remove duplicates of same indices\n",
    "        remove_indices=remove_indices.astype(int)\n",
    "        print('Total spectra with weak components in testing dataset:',np.unique(remove_indices).shape)    \n",
    "\n",
    "        \n",
    "        self.test_mixtures=np.delete(self.test_mixtures, remove_indices, 0)\n",
    "        self.test_targets=np.delete(self.test_targets, remove_indices, 0)\n",
    "\n",
    "        print('test_mixtures data type: ', self.test_mixtures.dtype)\n",
    "        print('test_mixtures shape: ', self.test_targets.shape)\n",
    "\n",
    "        print('test_targets data type: ', self.test_mixtures.dtype)\n",
    "        print('test_targets shape: ', self.test_targets.shape)\n",
    "        #Adjust the number of test mixtures\n",
    "        self.n_test_mixtures = self.n_test_mixtures - remove_indices.shape[0]\n",
    "        print('Adjusted n_test_mixtures after removing spectra with weak components: ', self.n_test_mixtures)\n",
    "        \n",
    "        t_end = datetime.now()\n",
    "        delta = t_end - t_start\n",
    "        Time_OVR=delta.total_seconds() * 1000\n",
    "        print('ASAT Time elasped:',Time_OVR)\n",
    "        \n",
    "        \n",
    "        if save_to_file == True:\n",
    "        \n",
    "            today = date.today()\n",
    "            now = datetime.now()\n",
    "\n",
    "            print(\"now =\", now)\n",
    "            # dd/mm/YY H:M:S\n",
    "            dt_string = now.strftime(\"%d-%m-%Y_time_%H-%M-%S\")\n",
    "            print(\"date and time =\", dt_string)\t\n",
    "\n",
    "            data_identifier = 'datasets' + '/' + 'N_mix = ' + str(self.n_test_mixtures) + '_' + dt_string + '_'\n",
    "\n",
    "            np.save(data_identifier + 'TSMC_Net_data_test_mixtures_weak_rm', self.test_mixtures)\n",
    "            np.save(data_identifier + 'TSMC_Net_data_test_targets_weak_rm', self.test_targets)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #########\n",
    "        # implement RSAT here\n",
    "        print('reimplementing RSAT')\n",
    "        t_start = datetime.now()\n",
    "        \n",
    "        remove_indices = np.array([])\n",
    "        # for i in range(y_test.shape[0]):\n",
    "        for i in tqdm(range(self.n_test_mixtures)):\n",
    "            species_max_abs_contribution = [np.amax(np.dot(self.basis[lc], self.test_targets[i][lc])) for lc in range(self.n_mixture_component_max)]\n",
    "            strongest_absorber_abs = max(species_max_abs_contribution)\n",
    "        #     print(i)\n",
    "            for _ in range(self.n_mixture_component_max):\n",
    "                \n",
    "                \n",
    "#                 print(strongest_absorber_abs)\n",
    "#                 import pdb; pdb.set_trace()\n",
    "                RSAT_calculated = np.amax(np.dot(self.basis[_],self.test_targets[i][_])/strongest_absorber_abs)\n",
    "    \n",
    "    \n",
    "#                 print(f'species id: {self.labels[_]} RSAT_calc = {RSAT_calculated}    RSAT = {RSAT}')\n",
    "                if RSAT_calculated < RSAT and RSAT_calculated > 0:\n",
    "                    if debug == True:\n",
    "                        print(f'species id: {self.labels[_]} RSAT_calc = {RSAT_calculated}    RSAT = {RSAT}')\n",
    "                    remove_indices=np.append(remove_indices, i)\n",
    "                    break\n",
    "#                     print('removed spectra containing relatively weak species')\n",
    "        \n",
    "        remove_indices=np.unique(remove_indices) #Remove duplicates of same indices\n",
    "        remove_indices=remove_indices.astype(int)\n",
    "        print('Total spectra with weak relative components in testing dataset:',np.unique(remove_indices).shape)    \n",
    "\n",
    "        \n",
    "        self.test_mixtures=np.delete(self.test_mixtures, remove_indices, 0)\n",
    "        self.test_targets=np.delete(self.test_targets, remove_indices, 0)\n",
    "\n",
    "        print('test_mixtures data type: ', self.test_mixtures.dtype)\n",
    "        print('test_mixtures shape: ', self.test_targets.shape)\n",
    "\n",
    "        print('test_targets data type: ', self.test_mixtures.dtype)\n",
    "        print('test_targets shape: ', self.test_targets.shape)\n",
    "        #Adjust the number of test mixtures\n",
    "        self.n_test_mixtures = self.n_test_mixtures - remove_indices.shape[0]\n",
    "        print('Adjusted n_test_mixtures after removing spectra with relatively weak speices: ', self.n_test_mixtures)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ###########\n",
    "        \n",
    "        t_end = datetime.now()\n",
    "        delta = t_end - t_start\n",
    "        Time_OVR=delta.total_seconds() * 1000\n",
    "        print('RSAT Time elasped:',Time_OVR)\n",
    "        \n",
    "        if save_to_file == True:\n",
    "        \n",
    "            today = date.today()\n",
    "            now = datetime.now()\n",
    "\n",
    "            print(\"now =\", now)\n",
    "            # dd/mm/YY H:M:S\n",
    "            dt_string = now.strftime(\"%d-%m-%Y_time_%H-%M-%S\")\n",
    "            print(\"date and time =\", dt_string)\t\n",
    "\n",
    "            data_identifier = 'datasets' + '/' + 'N_mix = ' + str(self.n_test_mixtures) + '_' + dt_string + '_'\n",
    "\n",
    "            np.save(data_identifier + 'TSMC_Net_data_test_mixtures_weak_rel_spec', self.test_mixtures)\n",
    "            np.save(data_identifier + 'TSMC_Net_data_test_targets_weak_rel_spec', self.test_targets)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.test_mixtures = self.test_mixtures.reshape(self.n_test_mixtures,self.n_features)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1740b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAAT = 0.001 \n",
    "# ASAT=0.01\n",
    "ASAT=0.005\n",
    "# RSAT=0.05\n",
    "RSAT=0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ba1a9ee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Components :  [[ 0  1  2  3  4  5  6  7  8  9 10 11 12]]\n",
      "Components shape :  (1, 13)\n",
      "TAAT =  0.001\n",
      "ASAT =  0.005\n",
      "RSAT =  0.005\n",
      "['$C_2H_5OH$', '$CH_3CHO$', '$CH_3Cl$', '$CH_3CN$', '$CH_3OH$', '$H_2CO$', '$H_2S$', '$HCN$', '$HCOOH$', '$HNO_3$', '$OCS$', '$SO_2$']\n"
     ]
    }
   ],
   "source": [
    "m = THz_mixture_data(resolution=0.016, pressure='1 Torr', verbosity=False)\n",
    "m.initiate_THz_mixture_data(TAAT = TAAT, \n",
    "                               ASAT=ASAT, \n",
    "                               RSAT=RSAT)\n",
    "\n",
    "reduced_labels = m.labels\n",
    "reduced_labels.remove('')\n",
    "reduced_labels.remove(' ')\n",
    "reduced_labels.remove('Diluent')\n",
    "print(reduced_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c4dccb21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ...generating 1-component mixtures data...\n",
      "\n",
      "total_attempts: 1\n",
      "Generator Time elasped: 1.8090000000000002\n",
      "\n",
      " ...generating 2-component mixtures data...\n",
      "\n",
      "total_attempts: 1\n",
      "Generator Time elasped: 1.5\n",
      "\n",
      " ...generating 3-component mixtures data...\n",
      "\n",
      "total_attempts: 2\n",
      "Generator Time elasped: 2.937\n",
      "\n",
      " ...generating 4-component mixtures data...\n",
      "\n",
      "total_attempts: 1\n",
      "Generator Time elasped: 1.487\n",
      "\n",
      " ...generating 5-component mixtures data...\n",
      "\n",
      "total_attempts: 7\n",
      "Generator Time elasped: 10.231\n",
      "\n",
      " ...generating 6-component mixtures data...\n",
      "\n",
      "total_attempts: 1\n",
      "Generator Time elasped: 1.484\n",
      "\n",
      " ...generating 7-component mixtures data...\n",
      "\n",
      "total_attempts: 7\n",
      "Generator Time elasped: 8.602\n",
      "\n",
      " ...generating 8-component mixtures data...\n",
      "\n",
      "total_attempts: 4\n",
      "Generator Time elasped: 5.538\n",
      "\n",
      " ...generating 9-component mixtures data...\n",
      "\n",
      "total_attempts: 11\n",
      "Generator Time elasped: 8.687000000000001\n",
      "\n",
      " ...generating 10-component mixtures data...\n",
      "\n",
      "total_attempts: 4\n",
      "Generator Time elasped: 2.903\n",
      "\n",
      " ...generating 11-component mixtures data...\n",
      "\n",
      "total_attempts: 71\n",
      "Generator Time elasped: 33.51\n",
      "\n",
      " ...generating 12-component mixtures data...\n",
      "\n",
      "total_attempts: 23485\n",
      "Generator Time elasped: 8855.25\n",
      "Time elasped: 8934.331\n",
      "Total number of test mixtures :  12\n",
      "\n",
      "Combined test simulated mixtures\n",
      "\n",
      "No. of test mixtures:  12\n",
      "test_targets data type:  object\n",
      "test_targets data shape:  (12, 12)\n",
      "Generating mixtures with TAAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 12/12 [00:00<00:00, 8435.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elaspsed:  4.2\n",
      "numpy random state:  3653637472\n",
      "\n",
      "reimplementing TAAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 12/12 [00:00<00:00, 76725.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total spectra with weak mixture spectra: (0,)\n",
      "test_mixtures data type:  object\n",
      "test_mixtures shape:  (12, 1, 229)\n",
      "test_targets data type:  object\n",
      "test_targets shape:  (12, 12)\n",
      "Adjusted n_test_mixtures:  12\n",
      "TAAT Time elasped: 2.7239999999999998\n",
      "reimplementing ASAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 12/12 [00:00<00:00, 2333.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total spectra with weak components in testing dataset: (0,)\n",
      "test_mixtures data type:  object\n",
      "test_mixtures shape:  (12, 12)\n",
      "test_targets data type:  object\n",
      "test_targets shape:  (12, 12)\n",
      "Adjusted n_test_mixtures after removing spectra with weak components:  12\n",
      "ASAT Time elasped: 10.909\n",
      "reimplementing RSAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 12/12 [00:00<00:00, 1586.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total spectra with weak relative components in testing dataset: (0,)\n",
      "test_mixtures data type:  object\n",
      "test_mixtures shape:  (12, 12)\n",
      "test_targets data type:  object\n",
      "test_targets shape:  (12, 12)\n",
      "Adjusted n_test_mixtures after removing spectra with relatively weak speices:  12\n",
      "RSAT Time elasped: 11.862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "m.make_controlled_sim_mixtures(equal_amount = 1, \n",
    "                               TAAT = TAAT, \n",
    "                               ASAT=ASAT, \n",
    "                               RSAT=RSAT, \n",
    "                               save_to_file = False, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c66d163f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit = 0.1\n",
    "my_list = [0.0, 0.14550336639456582, 0.0, 0.6427969843402346, 0.0, 0.0, 0.0, 0.0, 0.01899831755720252, 0.18503790952156376, 0.014896761613456908, 0.02589947828667129]\n",
    "\n",
    "all (x > limit for x in my_list if x>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa3599f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m [np\u001b[38;5;241m.\u001b[39mamax(np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbasis[lc], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_targets[i][lc])) \u001b[38;5;28;01mfor\u001b[39;00m lc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39mn_mixture_component_max)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "[np.amax(np.dot(self.basis[lc], self.test_targets[i][lc])) for lc in range(self.n_mixture_component_max)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "795637fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mamax(np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39mbasis[lc],\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_targets[i][lc]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "np.amax(np.dot(self.basis[lc],self.test_targets[i][lc]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac039a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of test mixtures:  57679\n",
      "test mixtures shape:  (57679, 229)\n",
      "test targets shape:  (57679, 12)\n",
      "test dilutions shape:  (120000,)\n",
      "resolution:  0.016\n",
      "frequencies in the data [ 7.352  7.368  7.384  7.4    7.416  7.432  7.448  7.464  7.48   7.496\n",
      "  7.512  7.528  7.544  7.56   7.576  7.592  7.608  7.624  7.64   7.656\n",
      "  7.672  7.688  7.704  7.72   7.736  7.752  7.768  7.784  7.8    7.816\n",
      "  7.832  7.848  7.864  7.88   7.896  7.912  7.928  7.944  7.96   7.976\n",
      "  7.992  8.008  8.024  8.04   8.056  8.072  8.088  8.104  8.12   8.136\n",
      "  8.152  8.168  8.184  8.2    8.216  8.232  8.248  8.264  8.28   8.296\n",
      "  8.312  8.328  8.344  8.36   8.376  8.392  8.408  8.424  8.44   8.456\n",
      "  8.472  8.488  8.504  8.52   8.536  8.552  8.568  8.584  8.6    8.616\n",
      "  8.632  8.648  8.664  8.68   8.696  8.712  8.728  8.744  8.76   8.776\n",
      "  8.792  8.808  8.824  8.84   8.856  8.872  8.888  8.904  8.92   8.936\n",
      "  8.952  8.968  8.984  9.     9.016  9.032  9.048  9.064  9.08   9.096\n",
      "  9.112  9.128  9.144  9.16   9.176  9.192  9.208  9.224  9.24   9.256\n",
      "  9.272  9.288  9.304  9.32   9.336  9.352  9.368  9.384  9.4    9.416\n",
      "  9.432  9.448  9.464  9.48   9.496  9.512  9.528  9.544  9.56   9.576\n",
      "  9.592  9.608  9.624  9.64   9.656  9.672  9.688  9.704  9.72   9.736\n",
      "  9.752  9.768  9.784  9.8    9.816  9.832  9.848  9.864  9.88   9.896\n",
      "  9.912  9.928  9.944  9.96   9.976  9.992 10.008 10.024 10.04  10.056\n",
      " 10.072 10.088 10.104 10.12  10.136 10.152 10.168 10.184 10.2   10.216\n",
      " 10.232 10.248 10.264 10.28  10.296 10.312 10.328 10.344 10.36  10.376\n",
      " 10.392 10.408 10.424 10.44  10.456 10.472 10.488 10.504 10.52  10.536\n",
      " 10.552 10.568 10.584 10.6   10.616 10.632 10.648 10.664 10.68  10.696\n",
      " 10.712 10.728 10.744 10.76  10.776 10.792 10.808 10.824 10.84  10.856\n",
      " 10.872 10.888 10.904 10.92  10.936 10.952 10.968 10.984 11.   ]\n",
      "pressure:  1 Torr\n",
      "labels:  ['$C_2H_5OH$', '$CH_3CHO$', '$CH_3Cl$', '$CH_3CN$', '$CH_3OH$', '$H_2CO$', '$H_2S$', '$HCN$', '$HCOOH$', '$HNO_3$', '$OCS$', '$SO_2$']\n",
      "label_id:  [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "number of features:  229\n",
      "no. of compounds:  12\n",
      "no. of spectrum per compound in pure THz data:  164\n",
      "no. of spectra in pure THz data:  1968\n",
      "number ot maximum mixture components:  12\n",
      "integer indices for each of the mixture components [[ 0  1  2  3  4  5  6  7  8  9 10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "print('number of test mixtures: ',m.n_test_mixtures)\n",
    "print('test mixtures shape: ',m.test_mixtures.shape)\n",
    "print('test targets shape: ',m.test_targets.shape)\n",
    "print('test dilutions shape: ',m.test_dilution.shape)\n",
    "\n",
    "print('resolution: ',m.resolution)\n",
    "print('frequencies in the data', m.frequencies)\n",
    "\n",
    "print('pressure: ',m.pressure) \n",
    "print('labels: ',m.labels) \n",
    "print('label_id: ',m.label_id) \n",
    "\n",
    "print('number of features: ',m.n_features) \n",
    "print('no. of compounds: ',m.n_compounds)\n",
    "print('no. of spectrum per compound in pure THz data: ' ,m.n_spectrum)\n",
    "print('no. of spectra in pure THz data: ',m.n_spectra) \n",
    "\n",
    "print('number ot maximum mixture components: ',m.n_mixture_component_max)\n",
    "print('integer indices for each of the mixture components',m.components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4dcec72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.61553834655112e-08, 1.0037858401249274e-08,\n",
       "       3.865109928531873e-09, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 2.5157419055466236e-09, 6.608788756219406e-09,\n",
       "       4.572357142078091e-08, 1.0907796087342393e-07,\n",
       "       8.833512811641548e-09, 2.994164036084506e-09, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.4343981147755444e-09,\n",
       "       3.586265423773045e-09, 2.039079138622628e-08,\n",
       "       1.2891663633818258e-07, 6.452145361814593e-09,\n",
       "       2.0377699410681017e-09, 0.0, 4.621321150524128e-06,\n",
       "       5.271158242250021e-06, 2.0579420126326473e-05,\n",
       "       2.364427572879474e-05, 2.7451807128947996e-05,\n",
       "       3.226434463708689e-05, 3.847205542807747e-05,\n",
       "       4.667642574394224e-05, 5.784583136200219e-05,\n",
       "       7.362539127755163e-05, 9.700827488282148e-05,\n",
       "       0.00013395996363397658, 0.00019799719726998073,\n",
       "       0.0003264090989898686, 0.0006648213966099923,\n",
       "       0.0024622307455298593, 0.008635363396259229, 0.01244451769144323,\n",
       "       0.011257839125003426, 0.0037020684927990275, 0.0031368519918083307,\n",
       "       0.003343769748297329, 0.003867519076841369, 0.004679696714522724,\n",
       "       0.005873008993087391, 0.0076567613935576715, 0.010451833187313936,\n",
       "       0.015163486031638123, 0.0240151132541061, 0.04372459518112076,\n",
       "       0.10302058158442719, 0.45400201512146393, 2.418465019974203,\n",
       "       0.23264012814911206, 0.09559947653293599, 0.06587798053260849,\n",
       "       0.024194165201200088, 0.014489091618700475, 0.00987928096009729,\n",
       "       0.00721238091253447, 0.005509421030737001, 0.004350273350001042,\n",
       "       0.0035239005588686874, 0.002913383378123465, 0.0024492842932832535,\n",
       "       0.002088118655274053, 0.001801476890651821, 0.0015701404589748514,\n",
       "       0.0013807220029504886, 4.772109504407756e-05,\n",
       "       4.174707635336887e-05, 3.5563111540205896e-05, 0.0, 0.0, 0.0, 0.0,\n",
       "       7.313104649669786e-10, 1.9988393641457272e-09,\n",
       "       1.652307354026915e-08, 2.078933089970932e-08,\n",
       "       2.1596834041001647e-09, 7.661020446318498e-10, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       6.142573610655104e-10, 2.029920627502785e-09,\n",
       "       5.830668300674578e-08, 4.961700439887512e-09, 9.56197059395843e-10,\n",
       "       3.921648840941432e-10, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 2.5279005889158276e-10,\n",
       "       6.202609630711297e-10, 3.2916709865253047e-09,\n",
       "       3.271274342968265e-08, 1.2617649081462652e-09,\n",
       "       3.8614335017685003e-10, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.6065823598352716e-10,\n",
       "       9.058852229903431e-10, 4.433475309309947e-08,\n",
       "       1.6879635590856372e-09, 3.5542719741361873e-10,\n",
       "       1.495704402310009e-10, 6.694907145385467e-79,\n",
       "       2.6684719928036264e-78, 5.644797902289565e-76], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.test_mixtures[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10df49c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
