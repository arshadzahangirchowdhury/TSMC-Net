{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9472f796",
   "metadata": {},
   "source": [
    "# Results for TSMCN-8-L-229 with SNR=inf. Noise added test data is analyzed after experimental classification\n",
    "\n",
    "RSAT=0.01 and 90 spectra per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4031617b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 14:56:46.788398: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-02 14:56:48.807393: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-02 14:56:49.726021: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:\n",
      "2022-11-02 14:56:49.726072: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-02 14:56:50.190431: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-02 14:56:54.342653: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:\n",
      "2022-11-02 14:56:54.342876: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:\n",
      "2022-11-02 14:56:54.342893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1-C combinations: 8\n",
      "Total 2-C combinations: 28\n",
      "Total 3-C combinations: 56\n",
      "Total 4-C combinations: 70\n",
      "Total 5-C combinations: 56\n",
      "Total 6-C combinations: 28\n",
      "Total 7-C combinations: 8\n",
      "Total 8-C combinations: 1\n",
      "Total combinations: 255\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns  #heat map\n",
    "import glob # batch processing of images\n",
    "\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix    #confusion matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Collect all the font names available to matplotlib\n",
    "font_names = [f.name for f in fm.fontManager.ttflist]\n",
    "# print(font_names)\n",
    "\n",
    "from scipy import signal\n",
    "from scipy import interpolate\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_curve \n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "#Sklearn model saving and loading\n",
    "from joblib import dump, load\n",
    "\n",
    "if '../../' not in sys.path:\n",
    "    sys.path.append('../../')\n",
    "\n",
    "from aimos.spectral_datasets.THz_datasets import THz_data\n",
    "\n",
    "from aimos.misc.utils import simple_plotter\n",
    "\n",
    "\n",
    "#Set random seed\n",
    "os.environ['PYTHONHASHSEED'] = str(42)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "tf.random.set_global_generator(42)\n",
    "\n",
    "tf.random.set_seed(42)  \n",
    "# tf.random.get_global_generator().reset_from_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "from oneida import THz_mixture_data\n",
    "from oneida_utils import concentrations_to_one_hot_encode, create_mixture_names\n",
    "from oneida_utils import simple_spectrum_fig, simple_plot_raw_scores, plot_spectrum_with_scores, multiclass_roc_auc_score, multiclass_sensitivity_specificity_score, multiclass_sensitivity_threshold_score\n",
    "from oneida_scoring_tools import calc_AMCAS, is_cui_present, is_cui_present_in_mult\n",
    "from aimos.misc.utils import classifier_internals\n",
    "from aimos.misc.utils import clf_post_processor\n",
    "from oneida_utils import mixture_names_to_one_hot_encode\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from oneida_grad_cam import grad_cam\n",
    "\n",
    "from stats import stats\n",
    "stats(n_compounds=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47e9f5e",
   "metadata": {},
   "source": [
    "# Retrieve training(D)+ validation(V) mixtures and its variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85ccc274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Components :  [[0 1 2 3 4 5 6 7 8]]\n",
      "Components shape :  (1, 9)\n",
      "TAAT =  0.001\n",
      "ASAT =  0.01\n",
      "RSAT =  0.01\n",
      "reduced_labels ['$C_2H_5OH$', '$CH_3CHO$', '$CH_3Cl$', '$CH_3CN$', '$CH_3OH$', '$H_2CO$', '$HCOOH$', '$HNO_3$']\n",
      "Number of neurons in the final layer : 255\n",
      "labels from class: ['$C_2H_5OH$', '$CH_3CHO$', '$CH_3Cl$', '$CH_3CN$', '$CH_3OH$', '$H_2CO$', '$HCOOH$', '$HNO_3$']\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "TAAT = 0.001 \n",
    "ASAT=0.01\n",
    "RSAT=0.01\n",
    "\n",
    "m = THz_mixture_data(resolution=0.016, pressure='1 Torr', verbosity=False)\n",
    "m.initiate_THz_mixture_data(TAAT = TAAT, \n",
    "                               ASAT=ASAT, \n",
    "                               RSAT=RSAT)\n",
    "\n",
    "reduced_labels = m.labels\n",
    "reduced_labels.remove('')\n",
    "reduced_labels.remove(' ')\n",
    "reduced_labels.remove('Diluent')\n",
    "print('reduced_labels', reduced_labels)\n",
    "\n",
    "\n",
    "# data_filename = \"datasets/TSMCN-5-L-229_DV_04-09-2022_time_22-26-37.pkl\"\n",
    "data_filename = \"datasets/TSMCN-8-L-229_DV__TAAT_0.001_ASAT_0.01_RSAT_0.01_20-10-2022_time_23-16-29_class_cnt_90.pkl\"\n",
    "DV = pd.read_pickle(data_filename)\n",
    "y = DV['y'].to_numpy()\n",
    "mixture_names = DV['mixture_names'].to_numpy()\n",
    "y_concentrations = DV[['y_c0', 'y_c1', 'y_c2','y_c3', 'y_c4', 'y_c5', 'y_c6', 'y_c7']].to_numpy()\n",
    "X = DV.drop(['y','mixture_names', 'y_c0', 'y_c1', 'y_c2','y_c3', 'y_c4', 'y_c5', 'y_c6', 'y_c7'],axis=1).to_numpy()\n",
    "\n",
    "final_neuron_number = np.unique(y, axis=0).shape[0]\n",
    "print('Number of neurons in the final layer :', final_neuron_number)\n",
    "\n",
    "print('labels from class:', m.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc09995e",
   "metadata": {},
   "source": [
    "# preview one test mixture spectra using simple plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bfcb777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 239\n",
    "# simple_plotter(m.frequencies,X[idx],linewidth=0.5,color='black',label=mixture_names[idx], \n",
    "#                    majorsize=6,minorsize=2,width=1, labelsize=8,legendsize=3, legendloc=2,  \n",
    "#                    labelpad=4,fontsize='medium',fontweight='bold',\n",
    "#                   xmajormplloc=0.5,xminormplloc=0.2, tickdirection='out')\n",
    "\n",
    "# print(y_concentrations[idx])\n",
    "# print(reduced_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d307a6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$CH_3CHO$' '$CH_3CHO$+$CH_3CN$' '$CH_3CHO$+$CH_3CN$+$CH_3OH$'\n",
      " '$CH_3CHO$+$CH_3CN$+$CH_3OH$+$HCOOH$'\n",
      " '$CH_3CHO$+$CH_3CN$+$CH_3OH$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3CHO$+$CH_3CN$+$CH_3OH$+$HNO_3$'\n",
      " '$CH_3CHO$+$CH_3CN$+$CH_3OH$+$H_2CO$'\n",
      " '$CH_3CHO$+$CH_3CN$+$CH_3OH$+$H_2CO$+$HCOOH$'\n",
      " '$CH_3CHO$+$CH_3CN$+$CH_3OH$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3CHO$+$CH_3CN$+$CH_3OH$+$H_2CO$+$HNO_3$'\n",
      " '$CH_3CHO$+$CH_3CN$+$HCOOH$' '$CH_3CHO$+$CH_3CN$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3CHO$+$CH_3CN$+$HNO_3$' '$CH_3CHO$+$CH_3CN$+$H_2CO$'\n",
      " '$CH_3CHO$+$CH_3CN$+$H_2CO$+$HCOOH$'\n",
      " '$CH_3CHO$+$CH_3CN$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3CHO$+$CH_3CN$+$H_2CO$+$HNO_3$' '$CH_3CHO$+$CH_3Cl$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$CH_3CN$' '$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$CH_3OH$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$CH_3OH$+$HCOOH$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$CH_3OH$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$CH_3OH$+$HNO_3$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$CH_3OH$+$H_2CO$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$CH_3OH$+$H_2CO$+$HCOOH$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$CH_3OH$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$CH_3OH$+$H_2CO$+$HNO_3$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$HCOOH$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$HNO_3$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$H_2CO$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$H_2CO$+$HCOOH$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$H_2CO$+$HNO_3$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$CH_3OH$' '$CH_3CHO$+$CH_3Cl$+$CH_3OH$+$HCOOH$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$CH_3OH$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$CH_3OH$+$HNO_3$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$CH_3OH$+$H_2CO$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$CH_3OH$+$H_2CO$+$HCOOH$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$CH_3OH$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$CH_3OH$+$H_2CO$+$HNO_3$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$HCOOH$' '$CH_3CHO$+$CH_3Cl$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$HNO_3$' '$CH_3CHO$+$CH_3Cl$+$H_2CO$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$H_2CO$+$HCOOH$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3CHO$+$CH_3Cl$+$H_2CO$+$HNO_3$' '$CH_3CHO$+$CH_3OH$'\n",
      " '$CH_3CHO$+$CH_3OH$+$HCOOH$' '$CH_3CHO$+$CH_3OH$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3CHO$+$CH_3OH$+$HNO_3$' '$CH_3CHO$+$CH_3OH$+$H_2CO$'\n",
      " '$CH_3CHO$+$CH_3OH$+$H_2CO$+$HCOOH$'\n",
      " '$CH_3CHO$+$CH_3OH$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3CHO$+$CH_3OH$+$H_2CO$+$HNO_3$' '$CH_3CHO$+$HCOOH$'\n",
      " '$CH_3CHO$+$HCOOH$+$HNO_3$' '$CH_3CHO$+$HNO_3$' '$CH_3CHO$+$H_2CO$'\n",
      " '$CH_3CHO$+$H_2CO$+$HCOOH$' '$CH_3CHO$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3CHO$+$H_2CO$+$HNO_3$' '$CH_3CN$' '$CH_3CN$+$CH_3OH$'\n",
      " '$CH_3CN$+$CH_3OH$+$HCOOH$' '$CH_3CN$+$CH_3OH$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3CN$+$CH_3OH$+$HNO_3$' '$CH_3CN$+$CH_3OH$+$H_2CO$'\n",
      " '$CH_3CN$+$CH_3OH$+$H_2CO$+$HCOOH$'\n",
      " '$CH_3CN$+$CH_3OH$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3CN$+$CH_3OH$+$H_2CO$+$HNO_3$' '$CH_3CN$+$HCOOH$'\n",
      " '$CH_3CN$+$HCOOH$+$HNO_3$' '$CH_3CN$+$HNO_3$' '$CH_3CN$+$H_2CO$'\n",
      " '$CH_3CN$+$H_2CO$+$HCOOH$' '$CH_3CN$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3CN$+$H_2CO$+$HNO_3$' '$CH_3Cl$' '$CH_3Cl$+$CH_3CN$'\n",
      " '$CH_3Cl$+$CH_3CN$+$CH_3OH$' '$CH_3Cl$+$CH_3CN$+$CH_3OH$+$HCOOH$'\n",
      " '$CH_3Cl$+$CH_3CN$+$CH_3OH$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3Cl$+$CH_3CN$+$CH_3OH$+$HNO_3$' '$CH_3Cl$+$CH_3CN$+$CH_3OH$+$H_2CO$'\n",
      " '$CH_3Cl$+$CH_3CN$+$CH_3OH$+$H_2CO$+$HCOOH$'\n",
      " '$CH_3Cl$+$CH_3CN$+$CH_3OH$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3Cl$+$CH_3CN$+$CH_3OH$+$H_2CO$+$HNO_3$' '$CH_3Cl$+$CH_3CN$+$HCOOH$'\n",
      " '$CH_3Cl$+$CH_3CN$+$HCOOH$+$HNO_3$' '$CH_3Cl$+$CH_3CN$+$HNO_3$'\n",
      " '$CH_3Cl$+$CH_3CN$+$H_2CO$' '$CH_3Cl$+$CH_3CN$+$H_2CO$+$HCOOH$'\n",
      " '$CH_3Cl$+$CH_3CN$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3Cl$+$CH_3CN$+$H_2CO$+$HNO_3$' '$CH_3Cl$+$CH_3OH$'\n",
      " '$CH_3Cl$+$CH_3OH$+$HCOOH$' '$CH_3Cl$+$CH_3OH$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3Cl$+$CH_3OH$+$HNO_3$' '$CH_3Cl$+$CH_3OH$+$H_2CO$'\n",
      " '$CH_3Cl$+$CH_3OH$+$H_2CO$+$HCOOH$'\n",
      " '$CH_3Cl$+$CH_3OH$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3Cl$+$CH_3OH$+$H_2CO$+$HNO_3$' '$CH_3Cl$+$HCOOH$'\n",
      " '$CH_3Cl$+$HCOOH$+$HNO_3$' '$CH_3Cl$+$HNO_3$' '$CH_3Cl$+$H_2CO$'\n",
      " '$CH_3Cl$+$H_2CO$+$HCOOH$' '$CH_3Cl$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3Cl$+$H_2CO$+$HNO_3$' '$CH_3OH$' '$CH_3OH$+$HCOOH$'\n",
      " '$CH_3OH$+$HCOOH$+$HNO_3$' '$CH_3OH$+$HNO_3$' '$CH_3OH$+$H_2CO$'\n",
      " '$CH_3OH$+$H_2CO$+$HCOOH$' '$CH_3OH$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$CH_3OH$+$H_2CO$+$HNO_3$' '$C_2H_5OH$' '$C_2H_5OH$+$CH_3CHO$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3CN$' '$C_2H_5OH$+$CH_3CHO$+$CH_3CN$+$CH_3OH$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3CN$+$CH_3OH$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3CN$+$CH_3OH$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3CN$+$CH_3OH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3CN$+$CH_3OH$+$H_2CO$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3CN$+$CH_3OH$+$H_2CO$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3CN$+$CH_3OH$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3CN$+$CH_3OH$+$H_2CO$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3CN$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3CN$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3CN$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3CN$+$H_2CO$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3CN$+$H_2CO$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3CN$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3CN$+$H_2CO$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$' '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3CN$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$CH_3OH$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$CH_3OH$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$CH_3OH$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$CH_3OH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$CH_3OH$+$H_2CO$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$CH_3OH$+$H_2CO$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$CH_3OH$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$CH_3OH$+$H_2CO$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$H_2CO$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$H_2CO$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3CN$+$H_2CO$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3OH$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3OH$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3OH$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3OH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3OH$+$H_2CO$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3OH$+$H_2CO$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3OH$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$CH_3OH$+$H_2CO$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$H_2CO$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$H_2CO$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3Cl$+$H_2CO$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3OH$' '$C_2H_5OH$+$CH_3CHO$+$CH_3OH$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3OH$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3OH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3OH$+$H_2CO$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3OH$+$H_2CO$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3OH$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$CH_3OH$+$H_2CO$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$HCOOH$' '$C_2H_5OH$+$CH_3CHO$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$HNO_3$' '$C_2H_5OH$+$CH_3CHO$+$H_2CO$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$H_2CO$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CHO$+$H_2CO$+$HNO_3$' '$C_2H_5OH$+$CH_3CN$'\n",
      " '$C_2H_5OH$+$CH_3CN$+$CH_3OH$' '$C_2H_5OH$+$CH_3CN$+$CH_3OH$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3CN$+$CH_3OH$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CN$+$CH_3OH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CN$+$CH_3OH$+$H_2CO$'\n",
      " '$C_2H_5OH$+$CH_3CN$+$CH_3OH$+$H_2CO$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3CN$+$CH_3OH$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CN$+$CH_3OH$+$H_2CO$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CN$+$HCOOH$' '$C_2H_5OH$+$CH_3CN$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CN$+$HNO_3$' '$C_2H_5OH$+$CH_3CN$+$H_2CO$'\n",
      " '$C_2H_5OH$+$CH_3CN$+$H_2CO$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3CN$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3CN$+$H_2CO$+$HNO_3$' '$C_2H_5OH$+$CH_3Cl$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$CH_3CN$' '$C_2H_5OH$+$CH_3Cl$+$CH_3CN$+$CH_3OH$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$CH_3CN$+$CH_3OH$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$CH_3CN$+$CH_3OH$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$CH_3CN$+$CH_3OH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$CH_3CN$+$CH_3OH$+$H_2CO$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$CH_3CN$+$CH_3OH$+$H_2CO$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$CH_3CN$+$CH_3OH$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$CH_3CN$+$CH_3OH$+$H_2CO$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$CH_3CN$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$CH_3CN$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$CH_3CN$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$CH_3CN$+$H_2CO$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$CH_3CN$+$H_2CO$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$CH_3CN$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$CH_3CN$+$H_2CO$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$CH_3OH$' '$C_2H_5OH$+$CH_3Cl$+$CH_3OH$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$CH_3OH$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$CH_3OH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$CH_3OH$+$H_2CO$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$CH_3OH$+$H_2CO$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$CH_3OH$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$CH_3OH$+$H_2CO$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$HCOOH$' '$C_2H_5OH$+$CH_3Cl$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$HNO_3$' '$C_2H_5OH$+$CH_3Cl$+$H_2CO$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$H_2CO$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3Cl$+$H_2CO$+$HNO_3$' '$C_2H_5OH$+$CH_3OH$'\n",
      " '$C_2H_5OH$+$CH_3OH$+$HCOOH$' '$C_2H_5OH$+$CH_3OH$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3OH$+$HNO_3$' '$C_2H_5OH$+$CH_3OH$+$H_2CO$'\n",
      " '$C_2H_5OH$+$CH_3OH$+$H_2CO$+$HCOOH$'\n",
      " '$C_2H_5OH$+$CH_3OH$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$CH_3OH$+$H_2CO$+$HNO_3$' '$C_2H_5OH$+$HCOOH$'\n",
      " '$C_2H_5OH$+$HCOOH$+$HNO_3$' '$C_2H_5OH$+$HNO_3$' '$C_2H_5OH$+$H_2CO$'\n",
      " '$C_2H_5OH$+$H_2CO$+$HCOOH$' '$C_2H_5OH$+$H_2CO$+$HCOOH$+$HNO_3$'\n",
      " '$C_2H_5OH$+$H_2CO$+$HNO_3$' '$HCOOH$' '$HCOOH$+$HNO_3$' '$HNO_3$'\n",
      " '$H_2CO$' '$H_2CO$+$HCOOH$' '$H_2CO$+$HCOOH$+$HNO_3$' '$H_2CO$+$HNO_3$']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(mixture_names)\n",
    "\n",
    "mixture_types=le.classes_\n",
    "print(mixture_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f19f87ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 22950)\n",
      "X_train shape: (13770, 229, 1)\n",
      "y_ohe_train shape: (13770,)\n",
      "X_val shape: (9180, 229, 1)\n",
      "y_ohe_val shape: (9180,)\n",
      "All: [0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686]\n",
      "Training: [0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686]\n",
      "Validation: [0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686 0.39215686\n",
      " 0.39215686 0.39215686 0.39215686]\n"
     ]
    }
   ],
   "source": [
    "#split intro train and validation set\n",
    "\n",
    "#seeds used 123,237, 786\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "global_indices=range(0, X.shape[0])\n",
    "print(global_indices)\n",
    "\n",
    "# (np.expand_dims(X,-1)\n",
    "TRAIN_SIZE=0.60\n",
    "VAL_SIZE=1-TRAIN_SIZE\n",
    "\n",
    "x_train, x_val, y_train, y_val, train_indices, val_indices = train_test_split(np.expand_dims(X, axis=-1), y, global_indices, train_size=TRAIN_SIZE,\n",
    "                                                   test_size=VAL_SIZE,\n",
    "                                                   random_state=786,\n",
    "                                                    stratify=y\n",
    "\n",
    "                                                   )\n",
    "\n",
    "print('X_train shape:', x_train.shape)\n",
    "print('y_ohe_train shape:', y_train.shape)\n",
    "\n",
    "print('X_val shape:', x_val.shape)\n",
    "print('y_ohe_val shape:', y_val.shape)\n",
    "\n",
    "\n",
    "print(\"All:\", np.bincount(y) / float(len(y))*100  )\n",
    "print(\"Training:\", np.bincount(y_train) / float(len(y_train))*100  )\n",
    "print(\"Validation:\", np.bincount(y_val) / float(len(y_val))*100  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23906391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from oneida_model import get_callbacks, get_optimizer, compile_and_fit, TSMCN_12_L_229"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1d6bbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 14:57:20.388728: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:\n",
      "2022-11-02 14:57:20.388916: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:\n",
      "2022-11-02 14:57:20.389014: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:\n",
      "2022-11-02 14:57:20.546779: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:\n",
      "2022-11-02 14:57:20.546977: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:\n",
      "2022-11-02 14:57:20.565274: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-11-02 14:57:20.566516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " C1 (Conv1D)                 (None, 227, 3)            12        \n",
      "                                                                 \n",
      " S2 (AveragePooling1D)       (None, 113, 3)            0         \n",
      "                                                                 \n",
      " C3 (Conv1D)                 (None, 111, 3)            30        \n",
      "                                                                 \n",
      " S4 (AveragePooling1D)       (None, 55, 3)             0         \n",
      "                                                                 \n",
      " C5 (Conv1D)                 (None, 53, 3)             30        \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 159)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 275)               44000     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 255)               70380     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 114,452\n",
      "Trainable params: 114,452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = TSMCN_12_L_229()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04097028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(model, to_file=\"RESULTS/TSMCN_8_L_229.png\", show_shapes=True, rankdir='TB', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "185b4ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSMCN-8-L-229_DV__TAAT_0.001_ASAT_0.01_RSAT_0.01_20-10-2022_time_23-16-29_class_cnt_90\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='checkpoints/',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "model_name = data_filename.split('.pkl')[0].split('/')[1]\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f53e6070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "431/431 [==============================] - 6s 10ms/step - loss: 3.5902 - SparseCatCrossentropy: 3.5880 - accuracy: 0.1279 - val_loss: 1.9684 - val_SparseCatCrossentropy: 1.9684 - val_accuracy: 0.3577\n",
      "Epoch 2/30\n",
      "431/431 [==============================] - 4s 9ms/step - loss: 1.2309 - SparseCatCrossentropy: 1.2299 - accuracy: 0.5730 - val_loss: 0.8607 - val_SparseCatCrossentropy: 0.8606 - val_accuracy: 0.6833\n",
      "Epoch 3/30\n",
      "431/431 [==============================] - 4s 9ms/step - loss: 0.5666 - SparseCatCrossentropy: 0.5662 - accuracy: 0.8085 - val_loss: 0.6709 - val_SparseCatCrossentropy: 0.6708 - val_accuracy: 0.7895\n",
      "Epoch 4/30\n",
      "431/431 [==============================] - 4s 10ms/step - loss: 0.3566 - SparseCatCrossentropy: 0.3563 - accuracy: 0.8802 - val_loss: 0.3483 - val_SparseCatCrossentropy: 0.3482 - val_accuracy: 0.8786\n",
      "Epoch 5/30\n",
      "431/431 [==============================] - 4s 9ms/step - loss: 0.2984 - SparseCatCrossentropy: 0.2980 - accuracy: 0.8988 - val_loss: 0.2712 - val_SparseCatCrossentropy: 0.2712 - val_accuracy: 0.9048\n",
      "Epoch 6/30\n",
      "431/431 [==============================] - 4s 9ms/step - loss: 0.2534 - SparseCatCrossentropy: 0.2532 - accuracy: 0.9174 - val_loss: 0.2724 - val_SparseCatCrossentropy: 0.2724 - val_accuracy: 0.9110\n",
      "Epoch 7/30\n",
      "431/431 [==============================] - 4s 9ms/step - loss: 0.2416 - SparseCatCrossentropy: 0.2415 - accuracy: 0.9229 - val_loss: 0.1610 - val_SparseCatCrossentropy: 0.1610 - val_accuracy: 0.9505\n",
      "Epoch 8/30\n",
      "431/431 [==============================] - 4s 9ms/step - loss: 0.2343 - SparseCatCrossentropy: 0.2340 - accuracy: 0.9243 - val_loss: 0.1884 - val_SparseCatCrossentropy: 0.1884 - val_accuracy: 0.9391\n",
      "Epoch 9/30\n",
      "431/431 [==============================] - 4s 9ms/step - loss: 0.1960 - SparseCatCrossentropy: 0.1958 - accuracy: 0.9357 - val_loss: 0.1712 - val_SparseCatCrossentropy: 0.1711 - val_accuracy: 0.9481\n",
      "Epoch 10/30\n",
      "431/431 [==============================] - 4s 9ms/step - loss: 0.1923 - SparseCatCrossentropy: 0.1920 - accuracy: 0.9373 - val_loss: 0.3829 - val_SparseCatCrossentropy: 0.3828 - val_accuracy: 0.8891\n",
      "Epoch 11/30\n",
      "431/431 [==============================] - 4s 9ms/step - loss: 0.1604 - SparseCatCrossentropy: 0.1607 - accuracy: 0.9503 - val_loss: 0.2429 - val_SparseCatCrossentropy: 0.2428 - val_accuracy: 0.9306\n",
      "Epoch 12/30\n",
      "431/431 [==============================] - 3s 8ms/step - loss: 0.1926 - SparseCatCrossentropy: 0.1926 - accuracy: 0.9378 - val_loss: 0.3581 - val_SparseCatCrossentropy: 0.3581 - val_accuracy: 0.9038\n",
      "Epoch 13/30\n",
      "431/431 [==============================] - 4s 10ms/step - loss: 0.1519 - SparseCatCrossentropy: 0.1517 - accuracy: 0.9530 - val_loss: 0.2023 - val_SparseCatCrossentropy: 0.2023 - val_accuracy: 0.9404\n",
      "Epoch 14/30\n",
      "431/431 [==============================] - 4s 9ms/step - loss: 0.1637 - SparseCatCrossentropy: 0.1635 - accuracy: 0.9497 - val_loss: 0.2273 - val_SparseCatCrossentropy: 0.2273 - val_accuracy: 0.9349\n",
      "Epoch 15/30\n",
      "431/431 [==============================] - 4s 9ms/step - loss: 0.1364 - SparseCatCrossentropy: 0.1367 - accuracy: 0.9561 - val_loss: 0.2144 - val_SparseCatCrossentropy: 0.2144 - val_accuracy: 0.9343\n",
      "Epoch 16/30\n",
      "431/431 [==============================] - 4s 9ms/step - loss: 0.1713 - SparseCatCrossentropy: 0.1711 - accuracy: 0.9478 - val_loss: 0.1593 - val_SparseCatCrossentropy: 0.1593 - val_accuracy: 0.9548\n",
      "Epoch 17/30\n",
      "431/431 [==============================] - 4s 9ms/step - loss: 0.1441 - SparseCatCrossentropy: 0.1442 - accuracy: 0.9548 - val_loss: 0.1507 - val_SparseCatCrossentropy: 0.1507 - val_accuracy: 0.9531\n",
      "Epoch 18/30\n",
      "431/431 [==============================] - 4s 9ms/step - loss: 0.1106 - SparseCatCrossentropy: 0.1105 - accuracy: 0.9649 - val_loss: 0.1787 - val_SparseCatCrossentropy: 0.1787 - val_accuracy: 0.9486\n",
      "Epoch 19/30\n",
      "431/431 [==============================] - 4s 10ms/step - loss: 0.1208 - SparseCatCrossentropy: 0.1208 - accuracy: 0.9640 - val_loss: 0.1175 - val_SparseCatCrossentropy: 0.1175 - val_accuracy: 0.9611\n",
      "Epoch 20/30\n",
      "431/431 [==============================] - 4s 9ms/step - loss: 0.1268 - SparseCatCrossentropy: 0.1274 - accuracy: 0.9610 - val_loss: 0.4798 - val_SparseCatCrossentropy: 0.4796 - val_accuracy: 0.8967\n",
      "Epoch 21/30\n",
      "431/431 [==============================] - 4s 9ms/step - loss: 0.1212 - SparseCatCrossentropy: 0.1223 - accuracy: 0.9644 - val_loss: 0.1883 - val_SparseCatCrossentropy: 0.1883 - val_accuracy: 0.9471\n",
      "Epoch 22/30\n",
      "431/431 [==============================] - 4s 9ms/step - loss: 0.1399 - SparseCatCrossentropy: 0.1398 - accuracy: 0.9596 - val_loss: 0.1943 - val_SparseCatCrossentropy: 0.1942 - val_accuracy: 0.9386\n",
      "Epoch 23/30\n",
      "431/431 [==============================] - 4s 9ms/step - loss: 0.1033 - SparseCatCrossentropy: 0.1032 - accuracy: 0.9676 - val_loss: 0.1107 - val_SparseCatCrossentropy: 0.1107 - val_accuracy: 0.9676\n",
      "Epoch 24/30\n",
      "431/431 [==============================] - 4s 9ms/step - loss: 0.1105 - SparseCatCrossentropy: 0.1104 - accuracy: 0.9654 - val_loss: 0.1511 - val_SparseCatCrossentropy: 0.1511 - val_accuracy: 0.9559\n",
      "Epoch 25/30\n",
      "431/431 [==============================] - 4s 9ms/step - loss: 0.1200 - SparseCatCrossentropy: 0.1199 - accuracy: 0.9626 - val_loss: 0.0982 - val_SparseCatCrossentropy: 0.0981 - val_accuracy: 0.9716\n",
      "Epoch 26/30\n",
      "431/431 [==============================] - 4s 9ms/step - loss: 0.1317 - SparseCatCrossentropy: 0.1317 - accuracy: 0.9596 - val_loss: 0.1676 - val_SparseCatCrossentropy: 0.1676 - val_accuracy: 0.9540\n",
      "Epoch 27/30\n",
      "431/431 [==============================] - 4s 10ms/step - loss: 0.0867 - SparseCatCrossentropy: 0.0872 - accuracy: 0.9732 - val_loss: 0.1714 - val_SparseCatCrossentropy: 0.1713 - val_accuracy: 0.9615\n",
      "Epoch 28/30\n",
      "431/431 [==============================] - 4s 8ms/step - loss: 0.0860 - SparseCatCrossentropy: 0.0859 - accuracy: 0.9742 - val_loss: 0.1241 - val_SparseCatCrossentropy: 0.1241 - val_accuracy: 0.9646\n",
      "Epoch 29/30\n",
      "431/431 [==============================] - 4s 9ms/step - loss: 0.1048 - SparseCatCrossentropy: 0.1049 - accuracy: 0.9684 - val_loss: 0.0870 - val_SparseCatCrossentropy: 0.0870 - val_accuracy: 0.9764\n",
      "Epoch 30/30\n",
      "431/431 [==============================] - 4s 10ms/step - loss: 0.1387 - SparseCatCrossentropy: 0.1388 - accuracy: 0.9606 - val_loss: 0.1214 - val_SparseCatCrossentropy: 0.1214 - val_accuracy: 0.9674\n"
     ]
    }
   ],
   "source": [
    "# run on CPU for reproducibility, best epoch is 4.\n",
    "# with tf.device('/CPU:0'):\n",
    "#      stop_early = tf.keras.callbacks.EarlyStopping(monitor='SparseCatCrossentropy', patience=5)\n",
    "#     history = model.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test), callbacks=[stop_early])\n",
    "\n",
    "# LambdaCallback(on_epoch_end=lambda batch, logs: print(model.layers[0].get_weights()))\n",
    "with tf.device('/CPU:0'):\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='SparseCatCrossentropy', patience=5)\n",
    "    history = model.fit(x_train, y_train, batch_size=32, epochs=30, validation_data=(x_val, y_val), \n",
    "                        callbacks=[model_checkpoint_callback, stop_early],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "508f61e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "431/431 [==============================] - 5s 12ms/step - loss: 0.0833 - SparseCatCrossentropy: 0.0832 - accuracy: 0.9745 - val_loss: 0.1240 - val_SparseCatCrossentropy: 0.1241 - val_accuracy: 0.9615\n",
      "Epoch 2/30\n",
      "431/431 [==============================] - 5s 12ms/step - loss: 0.0540 - SparseCatCrossentropy: 0.0539 - accuracy: 0.9828 - val_loss: 0.1004 - val_SparseCatCrossentropy: 0.1004 - val_accuracy: 0.9704\n",
      "Epoch 3/30\n",
      "431/431 [==============================] - 5s 12ms/step - loss: 0.0793 - SparseCatCrossentropy: 0.0792 - accuracy: 0.9744 - val_loss: 0.1182 - val_SparseCatCrossentropy: 0.1182 - val_accuracy: 0.9634\n",
      "Epoch 4/30\n",
      "431/431 [==============================] - 5s 12ms/step - loss: 0.0789 - SparseCatCrossentropy: 0.0788 - accuracy: 0.9778 - val_loss: 0.1058 - val_SparseCatCrossentropy: 0.1058 - val_accuracy: 0.9720\n",
      "Epoch 5/30\n",
      "431/431 [==============================] - 5s 11ms/step - loss: 0.0975 - SparseCatCrossentropy: 0.0974 - accuracy: 0.9691 - val_loss: 0.1631 - val_SparseCatCrossentropy: 0.1631 - val_accuracy: 0.9554\n",
      "Epoch 6/30\n",
      "431/431 [==============================] - 5s 11ms/step - loss: 0.0994 - SparseCatCrossentropy: 0.0993 - accuracy: 0.9697 - val_loss: 0.1609 - val_SparseCatCrossentropy: 0.1608 - val_accuracy: 0.9581\n",
      "Epoch 7/30\n",
      "431/431 [==============================] - 5s 12ms/step - loss: 0.0990 - SparseCatCrossentropy: 0.0988 - accuracy: 0.9714 - val_loss: 0.0853 - val_SparseCatCrossentropy: 0.0853 - val_accuracy: 0.9714\n"
     ]
    }
   ],
   "source": [
    "# run on CPU for reproducibility, best epoch is 4.\n",
    "# with tf.device('/CPU:0'):\n",
    "#      stop_early = tf.keras.callbacks.EarlyStopping(monitor='SparseCatCrossentropy', patience=5)\n",
    "#     history = model.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test), callbacks=[stop_early])\n",
    "\n",
    "# LambdaCallback(on_epoch_end=lambda batch, logs: print(model.layers[0].get_weights()))\n",
    "with tf.device('/CPU:0'):\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='SparseCatCrossentropy', patience=5)\n",
    "    history = model.fit(x_train, y_train, batch_size=32, epochs=30, validation_data=(x_val, y_val), \n",
    "                        callbacks=[model_checkpoint_callback, stop_early],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e96fa54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sklearn model saving and loading\n",
    "from joblib import dump, load\n",
    "import datetime\n",
    "from datetime import date, datetime\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d-%m-%Y_time_%H-%M-%S\")\n",
    "model.save('model/' + model_name + '_' + dt_string + '.hdf5')\n",
    "np.save('model/' + model_name + '_' + dt_string + 'history' + '.npy',history.history)\n",
    "np.save('model/' + model_name + '_' + dt_string + 'epoch' + '.npy',history.epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2cd08d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model('model/' + model_name + '_' + dt_string + '.hdf5', compile=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36cb79c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, \n",
    "                                         tf.keras.layers.Softmax()])\n",
    "predictions = probability_model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dba2fa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ohe = concentrations_to_one_hot_encode(y_concentrations).astype('int64')\n",
    "y_train_ohe = y_ohe[train_indices]\n",
    "y_val_ohe = y_ohe[val_indices]\n",
    "y_train_ohe_tensor = tf.convert_to_tensor(y_train_ohe, np.int64)\n",
    "y_val_ohe_tensor = tf.convert_to_tensor(y_val_ohe, np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dabc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.scatter(history.epoch,history.history['accuracy'], color = 'red', label = 'training')\n",
    "plt.scatter(history.epoch,history.history['val_accuracy'], color = 'blue', label = 'validation')\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig(r'RESULTS/results_figures/' + model_name + '_accuracies.png', bbox_inches='tight')\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.scatter(history.epoch,history.history['SparseCatCrossentropy'], color = 'red', label = 'training')\n",
    "plt.scatter(history.epoch,history.history['val_SparseCatCrossentropy'],color = 'blue', label = 'validation')\n",
    "plt.legend(loc=1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Sparse categorical crossentropy loss')\n",
    "plt.savefig(r'RESULTS/results_figures/'+ model_name + '_sparse_cat_losses.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bb2a16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
