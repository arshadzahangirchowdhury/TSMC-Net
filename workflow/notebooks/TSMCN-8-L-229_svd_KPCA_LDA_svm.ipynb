{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9472f796",
   "metadata": {},
   "source": [
    "# Results for TSMCN-8-L-229 with SNR=inf. Noise added test data is analyzed after experimental classification\n",
    "\n",
    "# SVM with various feature extraction methods\n",
    "\n",
    "### conclusion, can only achieve 85-87% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4031617b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns  #heat map\n",
    "import glob # batch processing of images\n",
    "\n",
    "import datetime\n",
    "import matplotlib.font_manager as fm\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import confusion_matrix    #confusion matrix\n",
    "\n",
    "\n",
    "# Collect all the font names available to matplotlib\n",
    "font_names = [f.name for f in fm.fontManager.ttflist]\n",
    "# print(font_names)\n",
    "\n",
    "from scipy import signal\n",
    "from scipy import interpolate\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_curve \n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "#Sklearn model saving and loading\n",
    "from joblib import dump, load\n",
    "\n",
    "if '../../' not in sys.path:\n",
    "    sys.path.append('../../')\n",
    "\n",
    "from aimos.spectral_datasets.THz_datasets import THz_data\n",
    "\n",
    "from aimos.misc.utils import simple_plotter\n",
    "\n",
    "\n",
    "#Set random seed\n",
    "os.environ['PYTHONHASHSEED'] = str(42)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "# tf.random.set_seed(42)  \n",
    "# tf.random.get_global_generator().reset_from_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "from oneida import THz_mixture_data\n",
    "from oneida_utils import concentrations_to_one_hot_encode, create_mixture_names\n",
    "from oneida_utils import simple_spectrum_fig, simple_plot_raw_scores, plot_spectrum_with_scores, multiclass_roc_auc_score, multiclass_sensitivity_specificity_score, multiclass_sensitivity_threshold_score\n",
    "from oneida_scoring_tools import calc_AMCAS, is_cui_present, is_cui_present_in_mult\n",
    "from aimos.misc.utils import classifier_internals\n",
    "from aimos.misc.utils import clf_post_processor\n",
    "from oneida_utils import mixture_names_to_one_hot_encode\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# from oneida_grad_cam import grad_cam\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from stats import stats\n",
    "stats(n_compounds=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47e9f5e",
   "metadata": {},
   "source": [
    "# Retrieve training(D)+ validation(V) mixtures and its variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ccc274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "TAAT = 0.001 \n",
    "ASAT=0.01\n",
    "RSAT=0.01\n",
    "\n",
    "m = THz_mixture_data(resolution=0.016, pressure='1 Torr', verbosity=False)\n",
    "m.initiate_THz_mixture_data(TAAT = TAAT, \n",
    "                               ASAT=ASAT, \n",
    "                               RSAT=RSAT)\n",
    "\n",
    "reduced_labels = m.labels\n",
    "reduced_labels.remove('')\n",
    "reduced_labels.remove(' ')\n",
    "reduced_labels.remove('Diluent')\n",
    "print('reduced_labels', reduced_labels)\n",
    "\n",
    "\n",
    "# data_filename = \"datasets/TSMCN-5-L-229_DV_04-09-2022_time_22-26-37.pkl\"\n",
    "data_filename = \"datasets/TSMCN-8-L-229_DV__TAAT_0.001_ASAT_0.01_RSAT_0.01_20-10-2022_time_23-16-29_class_cnt_90.pkl\"\n",
    "DV = pd.read_pickle(data_filename)\n",
    "y = DV['y'].to_numpy()\n",
    "mixture_names = DV['mixture_names'].to_numpy()\n",
    "y_concentrations = DV[['y_c0', 'y_c1', 'y_c2','y_c3', 'y_c4', 'y_c5', 'y_c6', 'y_c7']].to_numpy()\n",
    "X = DV.drop(['y','mixture_names', 'y_c0', 'y_c1', 'y_c2','y_c3', 'y_c4', 'y_c5', 'y_c6', 'y_c7'],axis=1).to_numpy()\n",
    "\n",
    "final_neuron_number = np.unique(y, axis=0).shape[0]\n",
    "print('Number of neurons in the final layer :', final_neuron_number)\n",
    "\n",
    "print('labels from class:', m.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc09995e",
   "metadata": {},
   "source": [
    "# preview one test mixture spectra using simple plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfcb777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 239\n",
    "# simple_plotter(m.frequencies,X[idx],linewidth=0.5,color='black',label=mixture_names[idx], \n",
    "#                    majorsize=6,minorsize=2,width=1, labelsize=8,legendsize=3, legendloc=2,  \n",
    "#                    labelpad=4,fontsize='medium',fontweight='bold',\n",
    "#                   xmajormplloc=0.5,xminormplloc=0.2, tickdirection='out')\n",
    "\n",
    "# print(y_concentrations[idx])\n",
    "# print(reduced_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d307a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(mixture_names)\n",
    "\n",
    "mixture_types=le.classes_\n",
    "print(mixture_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16449456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e3593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=None)\n",
    "X_transformed = lda.fit(X, y).transform(X)\n",
    "print(X_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0aac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import KernelPCA\n",
    "# X, _ = load_digits(return_X_y=True)\n",
    "\n",
    "\n",
    "kPCA = KernelPCA(n_components=20, kernel='linear')\n",
    "X_transformed = kPCA.fit_transform(X)\n",
    "print(X_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ee6e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_csr = csr_matrix(X)\n",
    "svd = TruncatedSVD(n_components=8, n_iter=7, random_state=42)\n",
    "SVD = svd.fit(X_csr)\n",
    "\n",
    "X_transformed = SVD.transform(X_csr)\n",
    "\n",
    "print(svd.explained_variance_ratio_)\n",
    "\n",
    "print(svd.explained_variance_ratio_.sum())\n",
    "\n",
    "print(svd.singular_values_)\n",
    "\n",
    "print(X_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19f87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split intro train and validation set\n",
    "\n",
    "#seeds used 123,237, 786\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "global_indices=range(0, X.shape[0])\n",
    "print(global_indices)\n",
    "\n",
    "# (np.expand_dims(X,-1)\n",
    "TRAIN_SIZE=0.60\n",
    "VAL_SIZE=1-TRAIN_SIZE\n",
    "\n",
    "x_train, x_val, y_train, y_val, train_indices, val_indices = train_test_split(X_transformed, y, global_indices, train_size=TRAIN_SIZE,\n",
    "                                                   test_size=VAL_SIZE,\n",
    "                                                   random_state=786,\n",
    "                                                    stratify=y\n",
    "\n",
    "                                                   )\n",
    "\n",
    "print('X_train shape:', x_train.shape)\n",
    "print('y_ohe_train shape:', y_train.shape)\n",
    "\n",
    "print('X_val shape:', x_val.shape)\n",
    "print('y_ohe_val shape:', y_val.shape)\n",
    "\n",
    "\n",
    "print(\"All:\", np.bincount(y) / float(len(y))*100  )\n",
    "print(\"Training:\", np.bincount(y_train) / float(len(y_train))*100  )\n",
    "print(\"Validation:\", np.bincount(y_val) / float(len(y_val))*100  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c27aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OneVsRest (SVM-Linear Kernel)\n",
    "\n",
    "#Measure time elapsed\n",
    "t_start = datetime.datetime.now()\n",
    "\n",
    "classifier_OVR = OneVsRestClassifier(SVC(kernel='rbf',C = 10000,decision_function_shape = 'ovo',random_state=1)).fit(x_train, y_train)\n",
    "\n",
    "\n",
    "pred_y = classifier_OVR.predict(x_val)\n",
    "\n",
    "\n",
    "FCA_OVR=np.sum(pred_y == y_val) / float(len(y_val))\n",
    "print(\"Fraction Correct[Accuracy]:\", FCA_OVR)\n",
    "\n",
    "\n",
    "cm_OVR = confusion_matrix(y_val, pred_y)\n",
    "print(classification_report(y_val, pred_y))\n",
    "\n",
    "t_end = datetime.datetime.now()\n",
    "delta = t_end - t_start\n",
    "Time_OVR=delta.total_seconds() * 1000\n",
    "\n",
    "print('Time elaspsed: ', Time_OVR) # milliseconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04097028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(model, to_file=\"RESULTS/TSMCN_8_L_229.png\", show_shapes=True, rankdir='TB', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c301764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exps = ['2 Comp-mix_ 30 % CH3Cl - 70% CH3CN/Mix 50% Dilute CM-ACN.xlsx',\n",
    "'2 Comp-mix_ 30 % CH3Cl - 70% CH3CN/Pure Mix CM-ACN.xlsx',\n",
    "'2 Comp-mix_ 30 % CH3Cl - 70% CH3CN/Mix 90% Dilute CM-ACN.xlsx',\n",
    "'3 Comp-mix_ 90+% CH3OH + 5-% CH3CN + 5-% CH3CL/0.9 CH3OH + 0.05 CH3CN + 0.05 CH3Cl - 1.xlsx',\n",
    "'3 Comp-mix_ 90+% CH3OH + 5-% CH3CN + 5-% CH3CL/0.9 CH3OH + 0.05 CH3CN + 0.05 CH3Cl - 2.xlsx',\n",
    "'4 Comp-mix_ 67% CH3OH + 30% CH3CHO + 2% CH3Cl + 1% CH3CN/0.67 CH3OH + 0.3 CH3CHO + 0.02 CH3Cl + 0.01 CH3CN - v2.xlsx',\n",
    "'4 Comp-mix_ 67% CH3OH + 30% CH3CHO + 2% CH3Cl + 1% CH3CN/90% Dilute in N2 - 0.67 CH3OH + 0.3 CH3CHO + 0.02 CH3Cl + 0.01 CH3CN'       ]\n",
    "\n",
    "true_label=[81,81,81,82,82,19,19]\n",
    "exp_path = '../../data/Mixture_exp_data/'\n",
    "exp_filepath = '4 Comp-mix_ 67% CH3OH + 30% CH3CHO + 2% CH3Cl + 1% CH3CN/0.67 CH3OH + 0.3 CH3CHO + 0.02 CH3Cl + 0.01 CH3CN - v2.xlsx'\n",
    "\n",
    "\n",
    "def classify_exp(exp_path,exp_filepath,mixture_types,true_label, excel=True):\n",
    "    all_unique_labels= mixture_types\n",
    "    if excel:\n",
    "        df_exp1 = pd.read_excel(exp_path + exp_filepath)\n",
    "    else:\n",
    "        df_exp1 = pd.read_csv(exp_path + exp_filepath)\n",
    "\n",
    "\n",
    "    freq_exp1 = df_exp1[df_exp1.columns[0]].to_numpy()\n",
    "    abs_exp1 = df_exp1[df_exp1.columns[1]].to_numpy()\n",
    "    \n",
    "#     fft_filter(freq_exp1, abs_exp1, factor=75)\n",
    "    \n",
    "    dfy_resampled= signal.resample(abs_exp1, len(m.frequencies))\n",
    "    dfx_resampled= signal.resample(freq_exp1, len(m.frequencies))\n",
    "#     import pdb; pdb.set_trace()    \n",
    "    pred_exp_label = classifier_OVR.predict(SVD.transform(np.reshape(dfy_resampled, (1, 229) )))\n",
    "\n",
    "\n",
    "    print('Experiment name: ',exp_filepath.split('/')[0])\n",
    "    print('predicted index ', pred_exp_label)\n",
    "    print('predicted label', mixture_types[pred_exp_label])\n",
    "    \n",
    "\n",
    "    \n",
    "    return pred_exp_label\n",
    "idx = 0 \n",
    "for experiment in exps:\n",
    "    classify_exp(exp_path,experiment,mixture_types, true_label[idx],excel=True)\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72a9125",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859fd6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(dfy_resampled, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f9f67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_exp_label = classifier_OVR.predict(SVD.transform(dfy_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96fa54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sklearn model saving and loading\n",
    "from joblib import dump, load\n",
    "import datetime\n",
    "from datetime import date, datetime\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d-%m-%Y_time_%H-%M-%S\")\n",
    "model.save('model/' + model_name + '_' + dt_string + '.hdf5')\n",
    "np.save('model/' + model_name + '_' + dt_string + 'history' + '.npy',history.history)\n",
    "np.save('model/' + model_name + '_' + dt_string + 'epoch' + '.npy',history.epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb79c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, \n",
    "                                         tf.keras.layers.Softmax()])\n",
    "predictions = probability_model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba2fa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ohe = concentrations_to_one_hot_encode(y_concentrations).astype('int64')\n",
    "y_train_ohe = y_ohe[train_indices]\n",
    "y_val_ohe = y_ohe[val_indices]\n",
    "y_train_ohe_tensor = tf.convert_to_tensor(y_train_ohe, np.int64)\n",
    "y_val_ohe_tensor = tf.convert_to_tensor(y_val_ohe, np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dabc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "plt.scatter(history.epoch,history.history['accuracy'], color = 'red', label = 'training')\n",
    "plt.scatter(history.epoch,history.history['val_accuracy'], color = 'blue', label = 'validation')\n",
    "plt.legend(loc=4)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig(r'RESULTS/results_figures/' + model_name + '_accuracies.png', bbox_inches='tight')\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "plt.scatter(history.epoch,history.history['SparseCatCrossentropy'], color = 'red', label = 'training')\n",
    "plt.scatter(history.epoch,history.history['val_SparseCatCrossentropy'],color = 'blue', label = 'validation')\n",
    "plt.legend(loc=1)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Sparse categorical crossentropy loss')\n",
    "plt.savefig(r'RESULTS/results_figures/'+ model_name + '_sparse_cat_losses.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bb2a16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
